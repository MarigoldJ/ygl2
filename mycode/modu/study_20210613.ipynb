{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210613_study.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "g4kB4VEU_dXH"
      ],
      "authorship_tag": "ABX9TyN58T+vK3FIZ/L9iIHZuAsu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarigoldJ/ygl2/blob/main/mycode/modu/study_20210613.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpz5lePR_GUM"
      },
      "source": [
        "# Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA-nr7ZG4Qwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a091b2b-38b3-4b88-ae38-e36e3893f4e3"
      },
      "source": [
        "# Download datasets\n",
        "! mkdir dataset\n",
        "! wget -NP ./dataset https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/ThoraricSurgery.csv\n",
        "! wget -NP ./dataset https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/housing.csv\n",
        "! wget -NP ./dataset https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/iris.csv\n",
        "! wget -NP ./dataset https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/pima-indians-diabetes.csv\n",
        "! wget -NP ./dataset https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/sonar.csv\n",
        "! wget -NP ./dataset https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/wine.csv\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-14 08:22:13--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/ThoraricSurgery.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21257 (21K) [text/plain]\n",
            "Saving to: ‘./dataset/ThoraricSurgery.csv’\n",
            "\n",
            "ThoraricSurgery.csv 100%[===================>]  20.76K  --.-KB/s    in 0.001s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-14 08:22:13 (36.8 MB/s) - ‘./dataset/ThoraricSurgery.csv’ saved [21257/21257]\n",
            "\n",
            "--2021-06-14 08:22:13--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/housing.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49082 (48K) [text/plain]\n",
            "Saving to: ‘./dataset/housing.csv’\n",
            "\n",
            "housing.csv         100%[===================>]  47.93K  --.-KB/s    in 0.004s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-14 08:22:14 (13.2 MB/s) - ‘./dataset/housing.csv’ saved [49082/49082]\n",
            "\n",
            "--2021-06-14 08:22:14--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/iris.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4551 (4.4K) [text/plain]\n",
            "Saving to: ‘./dataset/iris.csv’\n",
            "\n",
            "iris.csv            100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-14 08:22:14 (48.5 MB/s) - ‘./dataset/iris.csv’ saved [4551/4551]\n",
            "\n",
            "--2021-06-14 08:22:14--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/pima-indians-diabetes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23279 (23K) [text/plain]\n",
            "Saving to: ‘./dataset/pima-indians-diabetes.csv’\n",
            "\n",
            "pima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.001s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-14 08:22:14 (40.7 MB/s) - ‘./dataset/pima-indians-diabetes.csv’ saved [23279/23279]\n",
            "\n",
            "--2021-06-14 08:22:14--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/sonar.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87776 (86K) [text/plain]\n",
            "Saving to: ‘./dataset/sonar.csv’\n",
            "\n",
            "sonar.csv           100%[===================>]  85.72K  --.-KB/s    in 0.005s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-14 08:22:15 (17.3 MB/s) - ‘./dataset/sonar.csv’ saved [87776/87776]\n",
            "\n",
            "--2021-06-14 08:22:15--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%AA%A8%EB%91%90%EC%9D%98_%EB%94%A5%EB%9F%AC%EB%8B%9D/dataset/wine.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 361279 (353K) [text/plain]\n",
            "Saving to: ‘./dataset/wine.csv’\n",
            "\n",
            "wine.csv            100%[===================>] 352.81K  --.-KB/s    in 0.01s   \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-14 08:22:15 (26.0 MB/s) - ‘./dataset/wine.csv’ saved [361279/361279]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoGDB2nh_Mxe"
      },
      "source": [
        "# import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is-WzDDRuJZq"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4kB4VEU_dXH"
      },
      "source": [
        "# 테스트 해본 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vNbZ0QV_hs-"
      },
      "source": [
        "## csv 파일에서 2차원 배열을 불러오는 두가지 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZrYcsdlvUt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca6727b-7220-4c11-a436-c4421cd61da1"
      },
      "source": [
        "d1 = pd.read_csv('./dataset/ThoraricSurgery.csv', header=None)\n",
        "d2 = np.loadtxt('./dataset/ThoraricSurgery.csv', delimiter=',')\n",
        "\n",
        "equal = d1.values == d2\n",
        "print((equal == False).sum())   # data1에 담긴 values가 곧 data2이다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JVyLejd8ocB",
        "outputId": "14737341-32c1-47ff-de91-99f4678c06b9"
      },
      "source": [
        "d1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(470, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOLHrQsM_Q8_"
      },
      "source": [
        "# 신경망 만들어서 학습시키기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_82aF0cM_xae"
      },
      "source": [
        "* 모델 compile 옵션([tensorflow 문서 링크](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile))\n",
        "    * loss ([문서 링크](https://keras.io/ko/losses/))\n",
        "        * `mean_absolute_error` : MAE\n",
        "        * `mean_absolute_percentage_error`\n",
        "        * `mean_squared_error` : MSE\n",
        "        * `mean_squared_logarithmic_error`\n",
        "        * `binary_crossentropy` : choose 1 or 2\n",
        "        * `categorical_crossentropy`\n",
        "        * `sparse_categorical_crossentropy`\n",
        "        * `hinge`\n",
        "        * `squared_hinge`\n",
        "        * `categorical_hinge`\n",
        "        * `kullback_leibler_divergence`\n",
        "        * `poisson`\n",
        "        * `logcosh`\n",
        "        * `cosine_proximity`\n",
        "    * optimizer\n",
        "        * `Adam`\n",
        "        * `RMSprop`\n",
        "        * `SGD`\n",
        "        * 그 외에 adamdelta, adagrad, adamax, ftrl, nadam, optimizer가 있음\n",
        "    * metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flPY3Kn8vHPv"
      },
      "source": [
        "seed = 77\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjrnhT1fvRXV"
      },
      "source": [
        "data1 = pd.read_csv('./dataset/ThoraricSurgery.csv', header=None)\n",
        "x1 = data1.values[:, :17]   # 470 samples, 17 features\n",
        "y1 = data1.values[:, 17]    # 470 samples, 1 classes"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmR102Pg-8Kh",
        "outputId": "d008055a-b4d3-4b75-d3b5-b8fe1646c83d"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(30, input_dim=17, activation='relu'))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "# 17 - 30 - 1 Layer\n",
        "\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "print(model1.summary())\n",
        "print()\n",
        "\n",
        "model1.fit(x1, y1, epochs=100, batch_size=10) # 470(데이터길이) = 10(배치크기) x 47(개)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                540       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 571\n",
            "Trainable params: 571\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Epoch 1/100\n",
            "47/47 [==============================] - 2s 2ms/step - loss: 0.8333 - accuracy: 0.1617\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.7931 - accuracy: 0.2021\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.4894\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.8511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f51f05efcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCw_eHZt8m0J",
        "outputId": "b18af374-1fa5-4e8a-95b5-bab0e7ebd64f"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(30, input_dim=17, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "# 17 - 30 - 1 Layer\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "print(model2.summary())\n",
        "print()\n",
        "\n",
        "model2.fit(x1, y1, epochs=100, batch_size=10) # 470(데이터길이) = 10(배치크기) x 47(개)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 30)                540       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 571\n",
            "Trainable params: 571\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Epoch 1/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 2.3962 - accuracy: 0.8085\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8511\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8511\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8426\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8468\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8468\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8489\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8489\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8511\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8489\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8511\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8489\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8468\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8511\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8511\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8511\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8489\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8511\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8489\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8447\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.8511\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8489\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8511\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8511\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8511\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8511\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.8511\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8468\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8511\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8489\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8489\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8468\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8511\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8468\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8511\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8489\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8511\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8511\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8489\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8511\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8511\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8489\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8511\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8511\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.8489\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8511\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8489\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8511\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8511\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8489\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8532\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8511\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8511\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8511\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8511\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8489\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8511\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8511\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8511\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8511\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8511\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8511\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8511\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8511\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8511\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8511\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8511\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8511\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8511\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8511\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8511\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8511\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8511\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8511\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8511\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8511\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8511\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8511\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8511\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8511\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8511\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8511\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8511\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8511\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8511\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8511\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8511\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8511\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8511\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8511\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8511\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8511\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8511\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8511\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8532\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8511\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8511\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8532\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f51f03d7a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa3cefw5-dVy",
        "outputId": "40f03838-7856-4d81-ee14-4ceb054f0f39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(30, input_dim=17, activation='relu'))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model3.compile(loss='mean_squared_error', optimizer='RMSprop', metrics=['mse'])\n",
        "\n",
        "model3.fit(x1, y1, epochs=100, batch_size=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1947 - mse: 0.1947\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1485 - mse: 0.1485\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1495 - mse: 0.1495\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1490 - mse: 0.1490\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1498 - mse: 0.1498\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1488 - mse: 0.1488\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1476 - mse: 0.1476\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1535 - mse: 0.1535\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1474 - mse: 0.1474\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1462 - mse: 0.1462\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1429 - mse: 0.1429\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1465 - mse: 0.1465\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1487 - mse: 0.1487\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1471 - mse: 0.1471\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1463 - mse: 0.1463\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1468 - mse: 0.1468\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1451 - mse: 0.1451\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1453 - mse: 0.1453\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1470 - mse: 0.1470\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1450 - mse: 0.1450\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1465 - mse: 0.1465\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1444 - mse: 0.1444\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1423 - mse: 0.1423\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1422 - mse: 0.1422\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1476 - mse: 0.1476\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1473 - mse: 0.1473\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1373 - mse: 0.1373\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1409 - mse: 0.1409\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1409 - mse: 0.1409\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1429 - mse: 0.1429\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1399 - mse: 0.1399\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1377 - mse: 0.1377\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1367 - mse: 0.1367\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1376 - mse: 0.1376\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1360 - mse: 0.1360\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1378 - mse: 0.1378\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1372 - mse: 0.1372\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1329 - mse: 0.1329\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1412 - mse: 0.1412\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1322 - mse: 0.1322\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1384 - mse: 0.1384\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1386 - mse: 0.1386\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1419 - mse: 0.1419\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1373 - mse: 0.1373\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1388 - mse: 0.1388\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.1350\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1329 - mse: 0.1329\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1362 - mse: 0.1362\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1347 - mse: 0.1347\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1358 - mse: 0.1358\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.1335\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1395 - mse: 0.1395\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1355 - mse: 0.1355\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.1350\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1355 - mse: 0.1355\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1310 - mse: 0.1310\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1363 - mse: 0.1363\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1330 - mse: 0.1330\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1319 - mse: 0.1319\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1313 - mse: 0.1313\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.1335\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1310 - mse: 0.1310\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1328 - mse: 0.1328\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1321 - mse: 0.1321\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1328 - mse: 0.1328\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1370 - mse: 0.1370\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1320 - mse: 0.1320\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.1335\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1323 - mse: 0.1323\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1280 - mse: 0.1280\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1298 - mse: 0.1298\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1358 - mse: 0.1358\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1326 - mse: 0.1326\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1322 - mse: 0.1322\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1304 - mse: 0.1304\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.1350\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1299 - mse: 0.1299\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1353 - mse: 0.1353\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1304 - mse: 0.1304\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1314 - mse: 0.1314\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1352 - mse: 0.1352\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1304 - mse: 0.1304\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1319 - mse: 0.1319\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1342 - mse: 0.1342\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1329 - mse: 0.1329\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1414 - mse: 0.1414\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1258 - mse: 0.1258\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1261\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1304 - mse: 0.1304\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1341 - mse: 0.1341\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1240 - mse: 0.1240\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1298 - mse: 0.1298\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1279 - mse: 0.1279\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1269 - mse: 0.1269\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.1290\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1287 - mse: 0.1287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f518dfec090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyQ9L_3iQO3E"
      },
      "source": [
        "# 제목 미정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIWsQc7nQP6T",
        "outputId": "49e148f4-74cb-4edd-8726-ee0c856bc44a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "col2 = ['pregnant', 'plasma', 'pressure', 'thickness', 'insulin', 'BMI', 'pedigree', 'age', 'class']\n",
        "data2 = pd.read_csv('./dataset/pima-indians-diabetes.csv', header=None, names=col2) # header=None 을 빼도됨\n",
        "data2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pregnant</th>\n",
              "      <th>plasma</th>\n",
              "      <th>pressure</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>pedigree</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
              "0           6     148        72         35        0  33.6     0.627   50      1\n",
              "1           1      85        66         29        0  26.6     0.351   31      0\n",
              "2           8     183        64          0        0  23.3     0.672   32      1\n",
              "3           1      89        66         23       94  28.1     0.167   21      0\n",
              "4           0     137        40         35      168  43.1     2.288   33      1\n",
              "..        ...     ...       ...        ...      ...   ...       ...  ...    ...\n",
              "763        10     101        76         48      180  32.9     0.171   63      0\n",
              "764         2     122        70         27        0  36.8     0.340   27      0\n",
              "765         5     121        72         23      112  26.2     0.245   30      0\n",
              "766         1     126        60          0        0  30.1     0.349   47      1\n",
              "767         1      93        70         31        0  30.4     0.315   23      0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA8MmY1WqSmj",
        "outputId": "36648928-8081-45a4-a88f-89358c222390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(data2.head())\n",
        "print()\n",
        "print(data2.info())\n",
        "print()\n",
        "print(data2.describe())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
            "0         6     148        72         35        0  33.6     0.627   50      1\n",
            "1         1      85        66         29        0  26.6     0.351   31      0\n",
            "2         8     183        64          0        0  23.3     0.672   32      1\n",
            "3         1      89        66         23       94  28.1     0.167   21      0\n",
            "4         0     137        40         35      168  43.1     2.288   33      1\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   pregnant   768 non-null    int64  \n",
            " 1   plasma     768 non-null    int64  \n",
            " 2   pressure   768 non-null    int64  \n",
            " 3   thickness  768 non-null    int64  \n",
            " 4   insulin    768 non-null    int64  \n",
            " 5   BMI        768 non-null    float64\n",
            " 6   pedigree   768 non-null    float64\n",
            " 7   age        768 non-null    int64  \n",
            " 8   class      768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "None\n",
            "\n",
            "         pregnant      plasma    pressure  ...    pedigree         age       class\n",
            "count  768.000000  768.000000  768.000000  ...  768.000000  768.000000  768.000000\n",
            "mean     3.845052  120.894531   69.105469  ...    0.471876   33.240885    0.348958\n",
            "std      3.369578   31.972618   19.355807  ...    0.331329   11.760232    0.476951\n",
            "min      0.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n",
            "25%      1.000000   99.000000   62.000000  ...    0.243750   24.000000    0.000000\n",
            "50%      3.000000  117.000000   72.000000  ...    0.372500   29.000000    0.000000\n",
            "75%      6.000000  140.250000   80.000000  ...    0.626250   41.000000    1.000000\n",
            "max     17.000000  199.000000  122.000000  ...    2.420000   81.000000    1.000000\n",
            "\n",
            "[8 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pe5Svd4utEq",
        "outputId": "cfa896af-ba55-416e-a995-2f6094ee17f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# pregnant의 값에 따라 class를 확인\n",
        "print(data2[['pregnant', 'class']].groupby(['pregnant'], as_index=False).mean().sort_values(by='pregnant', ascending=True))\n",
        "# as_index = True : 출력되는 Dataframe의 index가 pregnant 행이 됨.\n",
        "# mean() : pregnant별로 다른 행(class)의 값의 평균을 출력 -> 발병확률로 볼 수 있음"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    pregnant     class\n",
            "0          0  0.342342\n",
            "1          1  0.214815\n",
            "2          2  0.184466\n",
            "3          3  0.360000\n",
            "4          4  0.338235\n",
            "5          5  0.368421\n",
            "6          6  0.320000\n",
            "7          7  0.555556\n",
            "8          8  0.578947\n",
            "9          9  0.642857\n",
            "10        10  0.416667\n",
            "11        11  0.636364\n",
            "12        12  0.444444\n",
            "13        13  0.500000\n",
            "14        14  1.000000\n",
            "15        15  1.000000\n",
            "16        17  1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QpxV69uvJFM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}