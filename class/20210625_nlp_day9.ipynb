{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210625_nlp_day9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgc9VyIsXp/Jh8nN+5DLgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarigoldJ/ygl2/blob/main/class/20210625_nlp_day9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIM1bl5ChdJt"
      },
      "source": [
        "# BILSTM + CRF 개체명 인식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMLBhber3-Uc"
      },
      "source": [
        "[참고링크 - 위키독스](https://wikidocs.net/34156)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykuzDLNuhci_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344c00ff-f80e-4371-a22c-9e042b74c473"
      },
      "source": [
        "# ! pip install tensorflow==1.14.0\n",
        "! pip install keras==2.2.4\n",
        "# ! pip install tensorflow-gpu==1.14.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\r\u001b[K     |█                               | 10kB 24.7MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 26.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.4) (1.5.2)\n",
            "Installing collected packages: keras-applications, keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.4 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJIs0Z_sep-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e01444-b74c-44ef-ec97-d36d57bf0fad"
      },
      "source": [
        "! pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-rnclefo9\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-rnclefo9\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.5.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101078 sha256=0c791aef4c94134434c4280c61cfae4c6e7660a07f74dd95181bfaf97f500f50\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ln0ztm_c/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRetCkcNh-Oo"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wBwm11Kiudf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a99551-7049-436a-8a49-208089bcc332"
      },
      "source": [
        "! wget -NP ./ https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/NLP/dataset/ner_dataset.csv\n",
        "\n",
        "path_to_file_kaggle = './ner_dataset.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-25 02:57:38--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/NLP/dataset/ner_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14159575 (14M) [text/plain]\n",
            "Saving to: ‘./ner_dataset.csv’\n",
            "\n",
            "ner_dataset.csv     100%[===================>]  13.50M  40.5MB/s    in 0.3s    \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-25 02:57:39 (40.5 MB/s) - ‘./ner_dataset.csv’ saved [14159575/14159575]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5W6lqUNi25h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7c3ec529-8fb7-4de8-a9eb-b49e7c1ba916"
      },
      "source": [
        "# 캐글데이터 불러오기\n",
        "data = pd.read_csv(path_to_file_kaggle, encoding='latin1')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>NaN</td>\n",
              "      <td>they</td>\n",
              "      <td>PRP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>NaN</td>\n",
              "      <td>responded</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>NaN</td>\n",
              "      <td>attack</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1048575 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Sentence #           Word  POS Tag\n",
              "0        Sentence: 1      Thousands  NNS   O\n",
              "1                NaN             of   IN   O\n",
              "2                NaN  demonstrators  NNS   O\n",
              "3                NaN           have  VBP   O\n",
              "4                NaN        marched  VBN   O\n",
              "...              ...            ...  ...  ..\n",
              "1048570          NaN           they  PRP   O\n",
              "1048571          NaN      responded  VBD   O\n",
              "1048572          NaN             to   TO   O\n",
              "1048573          NaN            the   DT   O\n",
              "1048574          NaN         attack   NN   O\n",
              "\n",
              "[1048575 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btx5Nrvoje_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57470dee-e47f-4977-98e3-7bf1f65d042b"
      },
      "source": [
        "# 데이터 확인해보기\n",
        "print('데이터 행 개수 :', len(data))\n",
        "print('데이터 null값이 있는가? :', data.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 행 개수 : 1048575\n",
            "데이터 null값이 있는가? : True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HNrDebDjmHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ea2f32-2c1b-444f-8b6e-37479ac828c8"
      },
      "source": [
        "print('Sentence # 열의 중복을 제거한 값의 개수 :', data['Sentence #'].nunique())    # 문장 개수\n",
        "print('Word 열의 중복을 제거한 값의 개수 :', data['Word'].nunique())                # 단어 가짓수\n",
        "print('Tag 열의 중복을 제거한 값의 개수 :', data['Tag'].nunique())                  # 태그 가짓수"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence # 열의 중복을 제거한 값의 개수 : 47959\n",
            "Word 열의 중복을 제거한 값의 개수 : 35178\n",
            "Tag 열의 중복을 제거한 값의 개수 : 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL-KiZpKkLQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacf0f5e-1593-406c-dea9-9023487cb402"
      },
      "source": [
        "print('Tag 열의 각 값의 개수')\n",
        "print('='*30)\n",
        "print(data.groupby('Tag').size().reset_index(name='count'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tag 열의 각 값의 개수\n",
            "==============================\n",
            "      Tag   count\n",
            "0   B-art     402\n",
            "1   B-eve     308\n",
            "2   B-geo   37644\n",
            "3   B-gpe   15870\n",
            "4   B-nat     201\n",
            "5   B-org   20143\n",
            "6   B-per   16990\n",
            "7   B-tim   20333\n",
            "8   I-art     297\n",
            "9   I-eve     253\n",
            "10  I-geo    7414\n",
            "11  I-gpe     198\n",
            "12  I-nat      51\n",
            "13  I-org   16784\n",
            "14  I-per   17251\n",
            "15  I-tim    6528\n",
            "16      O  887908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MNUkKUZkqRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e80f7786-d219-4682-c39c-28573865a6d0"
      },
      "source": [
        "# null값 제거\n",
        "data = data.fillna(method='ffill')  # front fill\n",
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>they</td>\n",
              "      <td>PRP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>responded</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>attack</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Sentence #       Word  POS Tag\n",
              "1048570  Sentence: 47959       they  PRP   O\n",
              "1048571  Sentence: 47959  responded  VBD   O\n",
              "1048572  Sentence: 47959         to   TO   O\n",
              "1048573  Sentence: 47959        the   DT   O\n",
              "1048574  Sentence: 47959     attack   NN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lLezeeclGRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd19d28-9bb7-4939-8c4f-95ffc00f92a9"
      },
      "source": [
        "# null 값 제거가 잘 되었는지 확인\n",
        "print('데이터 null값이 있는가? :', data.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 null값이 있는가? : False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgLD_55NlTss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "ea4990ca-bbb2-44e9-d7b7-2c3b7edd5562"
      },
      "source": [
        "data['Word'] = data['Word'].str.lower()\n",
        "print('Word 열의 중복을 제거한 값의 개수 :', data['Word'].nunique())    # 단어 가짓수\n",
        "print()\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 열의 중복을 제거한 값의 개수 : 31817\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1TVEOQlfW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3b7352-0940-474f-fb9f-0228a3957956"
      },
      "source": [
        "func = lambda temp: [(w, t) for w, t in zip(temp['Word'].values.tolist(), temp['Tag'].values.tolist())]\n",
        "tagged_sentences = [t for t in data.groupby('Sentence #').apply(func)]\n",
        "print('전체 샘플의 개수 :', len(tagged_sentences))\n",
        "print()\n",
        "print(tagged_sentences[0])   # 첫번째 샘플 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 개수 : 47959\n",
            "\n",
            "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAbH4tazmOwA"
      },
      "source": [
        "#\n",
        "sentences, ner_tags = [], []\n",
        "for tagged_sentence in tagged_sentences:        # 샘플마다\n",
        "    sentence, tag_info = zip(*tagged_sentence)  # 단어->sentence, 개체명 태깅정보->tag_info\n",
        "    sentences.append(list(sentence))            # 단어정보 리스트에 저장\n",
        "    ner_tags.append(list(tag_info))             # 태깅정보 리스트에 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqqwGQrIm4CH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "7248effd-249f-492f-ac3d-ae112a60e988"
      },
      "source": [
        "print('샘플의 최대 길이 :', max(len(l) for l in sentences))             # 샘플문장의 최대 길이\n",
        "print('샘플의 평균 길이 :', sum(map(len, sentences)) / len(sentences))  # 샘플문장의 평균 길이\n",
        "\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이 : 104\n",
            "샘플의 평균 길이 : 21.863987989741236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ3LNqFan94a"
      },
      "source": [
        "src_tokenizer = Tokenizer(oov_token='OOV')      # 모든 단어들을 사용하지만, 인덱스 1에는 단어 'OOV'를 할당함.\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "tar_tokenizer = Tokenizer(lower=False)          # 태깅 정보들은 내부적으로 대문자 유지한채 저장.\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUZOTlQaodKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7558ffe5-e173-48ad-b23e-936f22e9dd10"
      },
      "source": [
        "vocab_size = len(src_tokenizer.index_word) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "\n",
        "print('단어 집합의 크기 :', vocab_size)     # 단어 정보 집합의 크기\n",
        "print('태그 집합의 크기 :', tag_size)       # 개체명 태깅 정보 집합의 크기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 31819\n",
            "태그 집합의 크기 : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh4RduLlouk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cd4bb2-0930-4f15-c8ef-26eda71634a3"
      },
      "source": [
        "print('단어 OOV의 인덱스 :', src_tokenizer.word_index['OOV'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XcxlyGSo548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed7835d-899d-4f5d-e002-e32231b2b651"
      },
      "source": [
        "x_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)\n",
        "\n",
        "print(sentences[0])     # 문장\n",
        "print(x_data[0])        # 문장 sesquence\n",
        "print()\n",
        "print(ner_tags[0])      # 태그\n",
        "print(y_data[0])        # 태그 sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
            "\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
            "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZNr9GTEpH85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715fdfd2-0709-4692-ad16-613eac9d094d"
      },
      "source": [
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "index_to_ner[0] = 'PAD'     # 원래 index 0 에 해당하는 태그가 없으므로 추가해줌.\n",
        "\n",
        "print(index_to_ner)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0YxpjEfpfRb"
      },
      "source": [
        "# 문장 길이 맞추기\n",
        "max_len = 70\n",
        "x_data_pad = pad_sequences(x_data, padding='post', maxlen=max_len)\n",
        "y_data_pad = pad_sequences(y_data, padding='post', maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixn4Q-Ssp4pw"
      },
      "source": [
        "# train, test data 나누기\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data_pad, y_data_pad, test_size=.2, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DOJB1qUqaku"
      },
      "source": [
        "# target data를 원핫인코딩하기 -> split이전에 이 시행을 해도 될듯\n",
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntF4LXYFqn7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dcfb30-43ea-47a3-b2f5-f217e4f82021"
      },
      "source": [
        "# 데이터 shape 확인\n",
        "print('Train Input  :', x_train.shape)\n",
        "print('Train Output :', y_train.shape)\n",
        "print('Test  Input  :', x_test.shape)\n",
        "print('Test  Output :', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Input  : (38367, 70)\n",
            "Train Output : (38367, 70, 18)\n",
            "Test  Input  : (9592, 70)\n",
            "Test  Output : (9592, 70, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghSmsRg6w9Oq"
      },
      "source": [
        "## F1-Score test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWHQLbTzxdoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12833654-6d03-45b0-bd8b-8e0523f31ac6"
      },
      "source": [
        "# 실제값\n",
        "true = ['B-PER', 'I-PER', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O']\n",
        "\n",
        "# 예측값\n",
        "pred = ['O'] * len(true)\n",
        "\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjXC7CCxisn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8c30d9-a11a-447b-b82f-fd08e2d19a57"
      },
      "source": [
        "# 정답 개수 세기\n",
        "hit = 0\n",
        "for t, p in zip(true, pred):\n",
        "    if t==p:\n",
        "        hit += 1\n",
        "\n",
        "# 정확도(accuracy)\n",
        "accuracy = hit / len(true)\n",
        "print(f'정확도 : {100*accuracy:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 : 78.26%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYGDsFLJx4J3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b349cb06-6496-404d-8cd2-dbea81ae252c"
      },
      "source": [
        "! pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 29.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=092d128e36d72cddafc2b07dcc1d0d2a303207a52b6008775a6fbdf70d925573\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOUwRtNJx-_j"
      },
      "source": [
        "# 정밀도(precision), 재현률(recall)\n",
        "# 정밀도 = TP / (TP + FP) : 특정 개체라고 예측한 경우 중 예측이 일치한 비율\n",
        "# 재현률 = TP / (TP + FN) : 특정 개체 중 정답을 맞춘 비율\n",
        "# f1 score = 2 * (정밀도 * 재현률) / (정밀도 + 재현률)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYdeboilyiTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea3e21a-8eac-4ad1-a1a5-28f823f61e02"
      },
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([true], [pred]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        MISC       0.00      0.00      0.00         1\n",
            "         PER       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.00      0.00      0.00         3\n",
            "   macro avg       0.00      0.00      0.00         3\n",
            "weighted avg       0.00      0.00      0.00         3\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLtyXboLzTog"
      },
      "source": [
        "## F1-score를 측정하는 콜백 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJxRoCO01i-l"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UuHWvlNyoJ5"
      },
      "source": [
        "class F1score(Callback):\n",
        "    \n",
        "    def __init__(self, value=0.0, use_char=True):\n",
        "        super(F1score, self).__init__()\n",
        "        self.value = value\n",
        "        self.use_char = use_char\n",
        "    \n",
        "    def sequences_to_tags(self, sequences):\n",
        "        result = []\n",
        "        for sequence in sequences:\n",
        "            tag = []\n",
        "            for pred in sequence:                       # seq로부터 예측값을 하나씩 꺼냄\n",
        "                pred_index = np.argmax(pred)            # [0 0 1 0 0]이라면 2를 반환\n",
        "                tag.append(index_to_ner[pred_index].replace('PAD', 'O'))\n",
        "            result.append(tag)\n",
        "        return result\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        '''\n",
        "        에포크 끝날 때 마다 실행되는 함수\n",
        "        '''\n",
        "        # char Embedding 사용하는 경우\n",
        "        if self.use_char:\n",
        "            x_test = self.validation_data[0]\n",
        "            x_char_test = self.validation_data[1]\n",
        "            y_test = self.validation_data[2]\n",
        "            y_predicted = self.model.predict([x_test, x_char_test])\n",
        "        else:\n",
        "            x_test = self.validation_data[0]\n",
        "            y_test = self.validation_data[1]\n",
        "            y_predicted = self.model.predict([x_test])\n",
        "        \n",
        "        pred_tags = self.sequences_to_tags(y_predicted)\n",
        "        test_tags = self.sequences_to_tags(y_test)\n",
        "\n",
        "        score = f1_score(pred_tags, test_tags)\n",
        "\n",
        "        print(f' - f1: {100*score:04.2f}')\n",
        "        print(classification_report(test_tags, pred_tags))\n",
        "\n",
        "        # F1 score가 지금까지 중 가장 높은 경우\n",
        "        if score > self.values:\n",
        "            print(f'f1_score improved from {self.value} to {score}, saving model to best_model.h5')\n",
        "            self.model.save('best_model.h5')\n",
        "            self.value = score\n",
        "        else:\n",
        "            print(f'f1_score did not impove from {self.value}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmfqpR6i2CwO"
      },
      "source": [
        "## 제목 미정 (여긴 망했어요)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8IgCdyM2lxW"
      },
      "source": [
        "1. 문장의 첫번째 단어에는 I가 나오지 않습니다.\n",
        "2. O-I 패턴은 나오지 않는다.\n",
        "3. B-I-I 패턴에서 개체명은 일관성을 유지합니다.\n",
        "    * ex : B-PER 다음에는 I-PER과 I-Org중 I-PER이 오는것이 맞다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di5oAUo910pm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "26775036-4511-4353-f222-ae144a034cf4"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from keras_contrib.layers import CRF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-419efd21f3c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_contrib/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# We import all keras backend functions here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# so that files in this repo can import both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# core and contrib backend functions with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmulti_gpu_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/multi_gpu_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# note: `Node` is an internal class,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# it isn't meant to be used by Keras users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mv2_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mbase_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mv2_objs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minitializers_v2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6XzrnQQ5Rp5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "6c7d077b-8ac5-41f1-a38d-e9a8e2b281c7"
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-302d65a62f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrf_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmulti_gpu_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/multi_gpu_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# note: `Node` is an internal class,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# it isn't meant to be used by Keras users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mv2_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mbase_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mv2_objs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minitializers_v2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ILYbgnTAlgr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "outputId": "dc2ecc6d-4490-4025-8f1e-febe531a8acb"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(50, activation=\"relu\")))\n",
        "crf = CRF(tag_size)\n",
        "model.add(crf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f013e66a1f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 946\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1082\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1084\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    854\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:292 call  *\n        test_output = self.viterbi_decoding(X, mask)\n    /usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:564 viterbi_decoding  *\n        argmin_tables = self.recursion(input_energy, mask, return_logZ=False)\n    /usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:521 _step  *\n        return self.step(input_energy_i, states, return_logZ)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:1913 wrapper  *\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4342 rnn  *\n        output_time_zero, _ = step_function(\n    /usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:463 step  *\n        m = K.slice(states[3], [0, t], [-1, 2])\n\n    AttributeError: module 'keras.backend' has no attribute 'slice'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-R8J0qXC9JD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "226574eb-b30a-41cd-f4ac-3348b745cba0"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-98cd3281928c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmulti_gpu_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/multi_gpu_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# note: `Node` is an internal class,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# it isn't meant to be used by Keras users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mv2_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mbase_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mv2_objs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minitializers_v2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfB6P2Y1EZnh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1bb0858-a32f-41a8-95eb-f13b21eafd48"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3YIHndTCPZf"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoFXYYtCR9j"
      },
      "source": [
        "## 기존의 seq2seq모델의 한계\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfVToEUPCcnh"
      },
      "source": [
        "* 입력시퀀스를 하나의 벡터표현으로 압축(context vector)\n",
        "    * 디코더는 이를 통해 출력 시퀀스를 만들어냄\n",
        "* 정보가 일부 손실된다는 단점"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm_XtewFCf_D"
      },
      "source": [
        "* $d_{model} = 512$\n",
        "* num_layers = 6\n",
        "* num_heads = 8\n",
        "* $d_{ff} = 2048$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60XQm1zhCfnX"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer1.PNG)\n",
        "![](https://wikidocs.net/images/page/31379/transformer2.PNG)\n",
        "![](https://wikidocs.net/images/page/31379/transformer4_final_final_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt1hg_LaFPfs"
      },
      "source": [
        "## 포지셔널 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DY7b4KCFTt1"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer5_final_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xCVpCVTFeVP"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer6_final.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqQ8I-AzFfCY"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer7.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keBB8vhjFgn-"
      },
      "source": [
        "- pos : 입력 문장에서의 임베딩 벡터의 위치 \n",
        "- i : 임베딩 벡터 내의 차원의 인덱스를 의미  \n",
        "(pos, 2i) -->사인함수, (pos, 2i+1) --> 코사인함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI3QQIrYJf2A"
      },
      "source": [
        "## 코드실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhRblohoJddb"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLiPKD8VBP0I"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "            d_model=d_model)\n",
        "\n",
        "        # 배열의 짝수 인덱스에는 sin함수 적용\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # 배열의 홀수 인덱스에는 cos함수 적용\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        angle_rads = np.zeros(angle_rads.shape)\n",
        "        angle_rads[:, 0::2] = sines\n",
        "        angle_rads[:, 1::2] = cosines\n",
        "        pos_encoding = tf.constant(angle_rads)\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "        print(pos_encoding.shape)\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz3e4JbiIC_3",
        "outputId": "088a37cb-5056-4320-f96f-f976e523bfa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# 50x 128크기를 가지는 포지셔널인코딩 행렬을 시각화해서 어떤 형태를 가지는지 봅시다.\n",
        "# 입력 문장의 단어가 50, 각 단어가 128차원의 임베딩 벡터를 가질 때 사용할 수 있는 행렬\n",
        "\n",
        "sample_pos_encoding = PositionalEncoding(50, 128)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap=\"RdBu\")\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0,128))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjydlVNnJnDU"
      },
      "source": [
        "## 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIt_-rzaJr07"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/attention.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkPlisKMJw1f"
      },
      "source": [
        "- 인코더 셀프 어텐션 : Query = Key = value\n",
        "- 디코더 마스크드 셀프 어텐션 : Query = Key = value\n",
        "- 디코더의 인코더-디코더 어텐션 : Query (디코더 벡터)  \n",
        "key = value (인코더 벡터)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ksr1F91J1Mr"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer_attention_overview.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCPIVM68mBJy"
      },
      "source": [
        "## 인코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhN_fP7gmHDv"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer9_final_ver.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nceOLQRqmHuY"
      },
      "source": [
        "## 셀프 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbA7dBF3mKFr"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)\n",
        "\n",
        "* Query(쿼리)에 대해서 모든 키(Key)의 유사도"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh5xG4mUmS-x"
      },
      "source": [
        "* seq2seq에서 Q,K,V\n",
        "    - Query : t시점의 디코더 셀에서의 은닉상태\n",
        "    - Key : 모든 시점의 인코더 셀의 은닉상태\n",
        "    - values : 모든 시점의 인코더 셀의 은닉상태\n",
        "\n",
        "* transformer에서 Q, K, V\n",
        "    - Query : 입력 문장의 모든 단어 벡터들\n",
        "    - Key : 입력 문장의 모든 단어 벡터들\n",
        "    - Value : 입력 문장의 모든 단어 벡터들"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WGWR0J6nwTU"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer10.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siFqFG5MnyJX"
      },
      "source": [
        "### Q, K, V 벡터 얻기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A6syoEan0iA"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer11.PNG)\n",
        "\n",
        "- $d_{model}$ = 512\n",
        "- $num_{heads}$ = 8\n",
        "- 512/8 = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul2n-wjbn7Do"
      },
      "source": [
        "### 스케일드 닷 프로덕트 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qS2Ngfqn_x9"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/transformer13.PNG)\n",
        "\n",
        "![](https://wikidocs.net/images/page/31379/transformer14_final.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Q3HG11JoyG"
      },
      "source": [
        "# 구현\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    '''\n",
        "    query size : (batch_size, num_heads, query_len, d_model/num_heads)\n",
        "    key size : (batch_size, num_heads, key_len, d_model/num_heads)\n",
        "    value size : (batch_size, num_heads, value_len, d_model/num_heads)\n",
        "    \n",
        "    padding mask : (batch_size, 1, 1, key_len)\n",
        "    '''\n",
        "\n",
        "    # Q와 K의 곱\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b = True)\n",
        "\n",
        "    # 스케일링\n",
        "    # dk의 루트값으로 나눠준다.\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # 마스킹 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
        "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
        "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
        "    attention_weight = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    # output : (batch_size, num_heads, query의 문장 길이 , d_model/num_heads)\n",
        "    output = tf.matmul(attention_weight, value)\n",
        "\n",
        "    return output, attention_weight"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD_-HnwSol7F"
      },
      "source": [
        "# scaled_dot_product_attention 함수가 정상적으로 작동하는지 테스트!\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10, 0, 0],\n",
        "                      [0, 10, 0],\n",
        "                      [0, 0, 10],\n",
        "                      [0, 0, 10]], dtype=tf.float32)    # (4,3)\n",
        "\n",
        "temp_v = tf.constant([[1, 0],\n",
        "                      [10, 0],\n",
        "                      [100, 5],\n",
        "                      [1000, 6]], dtype=tf.float32)     # (4,2)\n",
        "\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)    # (1,3)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICB_LWWrqStg",
        "outputId": "d917aa62-80bc-4213-e071-ad0c2da36380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 함수 실행\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn)        # 어텐션 분포 (어텐션 가중치)\n",
        "print(temp_out)         # 어텐션 값"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyvdPXA8rDmQ",
        "outputId": "37afb735-c05f-448a-806e-2e20cf4e1e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10, 0, 0],\n",
        "                      [0, 10, 0],\n",
        "                      [0, 0, 10],\n",
        "                      [0, 0, 10]], dtype=tf.float32)    # (4,3)\n",
        "\n",
        "temp_v = tf.constant([[1, 0],\n",
        "                      [10, 0],\n",
        "                      [100, 5],\n",
        "                      [1000, 6]], dtype=tf.float32)     # (4,2)\n",
        "\n",
        "temp_q = tf.constant([[0, 0, 10],\n",
        "                      [0, 10, 0],\n",
        "                      [10, 10, 0]], dtype=tf.float32)    # (1,3)\n",
        "\n",
        "# 함수 실행\n",
        "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
        "print(temp_attn)        # 어텐션 분포 (어텐션 가중치)\n",
        "print(temp_out)         # 어텐션 값"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.  0.  0.5 0.5]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[550.    5.5]\n",
            " [ 10.    0. ]\n",
            " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIR-McEEvTxw"
      },
      "source": [
        "## 멀티 헤드 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOwCPncRvWKD"
      },
      "source": [
        "* 병렬 어텐션의 효과\n",
        "    * 머리가 여러개, 따라서 여러 시점에서 상대방을 볼 수 있다.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKZUhbY9vqvz"
      },
      "source": [
        "1. $W_Q$, $W_K$, $W_V$에 해당하는 $d_{model}$ 크기의 밀집층(Dense Layer)을 지남\n",
        "2. 지정된 헤드 수(num_heads)만큼 나눔.\n",
        "3. 스케일드 닷 프로덕트 어텐션\n",
        "4. 나눠졌던 헤드들을 연결한다.\n",
        "5. $W_O$에 해당하는 밀집층을 지나게 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDFBUNlnrrb4"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, name='multi_head_attention'):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        # d_model을 num_heads로 나눈 값\n",
        "        # 논문 기준 64\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        # W_Q, W_K, W_V에 해당하는 밀집층 정의\n",
        "        self.query_dense = tf.keras.layer.Dense(d_model)\n",
        "        self.key_dense = tf.keras.layer.Dense(d_model)\n",
        "        self.value_dense = tf.keras.layer.Dense(d_model)\n",
        "\n",
        "        # W_Q에 해당하는 밀집층 정의\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    \n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        '''\n",
        "        num_heads개수만큼 q, k, v를 split하는 함수\n",
        "        '''\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape = (batch_size, -1, self.num_heads, self.depth)\n",
        "        )\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # 1. W_Q, W_K, W_K에 해당하는 밀집층 지나기\n",
        "        # q : (batch_size, query 문장길이, d_model)\n",
        "        # k : (batch_size, key   문장길이, d_model)\n",
        "        # v : (batch_size, value 문장길이, d_model)\n",
        "        # 참고 -> 인코더 (k, v) - 디코더 (q) 어텐션에서는 query길이와 key, value의 길이는 다를 수 있다.\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # 2. 헤드 나누기\n",
        "        # q : (batch_size, num_heads, query 문장길이, d_model/num_heads)\n",
        "        # k : (batch_size, num_heads, key   문장길이, d_model/num_heads)\n",
        "        # v : (batch_size, num_heads, value 문장길이, d_model/num_heads)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # 3. 스케일드 닷 프로덕트 어텐션\n",
        "        # (batch_size, num_heads, query 문장길이, d_model/num_heads)\n",
        "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "        # (batch_size, query 문장길이, num_heads, d_model/num_heads)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # 4. 헤드 연결\n",
        "        # (batch_size, query 문장길이, d_model)\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "        # 5. W_O에 해당하는 밀집층 지나기\n",
        "        # (batch_size, query 문장길이, d_model)\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5utCLiT3zbup"
      },
      "source": [
        "## 패딩 마스크"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlrlwvgQ0jtc"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/pad_masking11.PNG)\n",
        "\n",
        "![](https://wikidocs.net/images/page/31379/pad_masking2.PNG)\n",
        "\n",
        "![](https://wikidocs.net/images/page/31379/softmax.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gDG89JOzcyM"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "    # (batch_size, 1, 1, key 문장길이)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H2tigzL0U5s",
        "outputId": "c17eb637-d6a6-4c52-c957-354ecfc9ae2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZKj75UK0sCX"
      },
      "source": [
        "## 포지션-와이드 피드 포워드 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9jbiin60tdw"
      },
      "source": [
        "$$ FFNN(x) = MAX(0, xW_1 + B_1)W_2 + b_2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZENd6Abf02ZA"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/positionwiseffnn.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h0pWV0A1M5g"
      },
      "source": [
        "```\n",
        "outputs = tf.keras.layers.Dense(dff, activation='relu')(attention)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2Os-WAn1kvC"
      },
      "source": [
        "## 잔차 연결과 층 정규화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2IHcV_U1opC"
      },
      "source": [
        "* 잔차 연결 (Residual connection)\n",
        "\n",
        "$$H(x) = x + F(x)$$\n",
        "\n",
        "![](https://wikidocs.net/images/page/31379/transformer22.PNG)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFTgAmGG12nI"
      },
      "source": [
        "* 층 정규화 (Layer Normalization)\n",
        "$$LN = LayerNorm(H(x))$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqP2mg8E2Kvz"
      },
      "source": [
        "## 인코더 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKwDkYJq0YNI"
      },
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "    # 인코더는 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1,1,None), name=\"padding_mask\")\n",
        "\n",
        "    # 멀티-헤드 어텐션 (첫번째 서브층 /셀프 어텐션)\n",
        "    attention = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention\")({\n",
        "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "            'mask': padding_mask # 패딩 마스크 사용\n",
        "        })\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "        epsion=1e-6)(inputs + attention)\n",
        "\n",
        "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6(attention + outputs))\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tm2CSlZ7lDh"
      },
      "source": [
        "## 인코더 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1liwOM6M7ZWq"
      },
      "source": [
        "def encoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    # 인코더는 패딩마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name = \"padding_mask\")\n",
        "\n",
        "    #포지셔널 인코딩 + 드롭아웃\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # 인코딩를 num_layer개 쌓기\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "            dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, padding_mask], outputs=outputs, name=name\n",
        "    )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl1n6LJ99YWC"
      },
      "source": [
        "## 디코더의 첫번째 서브층 : self어텐션과 룩-헤드 마스크"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlN3Dzlb9dtE"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/decoder.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3CBfk_X_Th9"
      },
      "source": [
        "![](https://wikidocs.net/images/page/31379/%EB%A3%A9%EC%96%B4%ED%97%A4%EB%93%9C%EB%A7%88%EC%8A%A4%ED%81%AC.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r2CTlNe_V6o"
      },
      "source": [
        "- 인코더에 있는 self어텐션 : 패딩마스크전달\n",
        "- 디코더와 첫번째 서브층인 masked self attention : 룩-어헤드 마스크전달\n",
        "- 디코더의 두번째 서브층인 인코더-디코더 어텐션 : 패딩마스크전달"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKyAjSSn9bse"
      },
      "source": [
        "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 mask하는 함수\n",
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x) #패딩 마스크 포함\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcWP_nxR_X-E",
        "outputId": "ef92c5ea-e5b8-4647-9464-2a0a6f12c75f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1,2,0,4,5]])))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoD4H-Xa_cof"
      },
      "source": [
        "## 디코더의 두번째 서브층 : 인코더-디코더 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxbNcIjW_e0p"
      },
      "source": [
        "* 다시한번 서브층에서 Q, K, V 관계를 정리하자\n",
        "    * 인코더의 첫번째 서브층 : Query = Key = Value\n",
        "    * 디코더의 첫번째 서브층 : Query = Key = Value\n",
        "    * 디코더의 두번째 서브층 : Query (디코더 행렬) // Key = Value (인코더 행렬)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uevc9iCb_1I6"
      },
      "source": [
        "## 디코더 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8uacDfz_ee_"
      },
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outpus\")\n",
        "\n",
        "    # 룩어헤드 마스크(첫번째 서브층)\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "        shape = (1, None, None), name=\"look_ahead_mask\"\n",
        "    )\n",
        "\n",
        "    # 패딩마스크 (두번째 서브층)\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "    attention1 = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "            'query':inputs, 'key':inputs, 'value':inputs, # Q= K = V\n",
        "            'mask' : look_ahead_mask\n",
        "        })\n",
        "    \n",
        "    # 잔차 연결과 층 정규화\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(attention1+inputs)\n",
        "    \n",
        "    # 멀티 헤드 어텐션 (두번째 서브층/ 디코더-인코더 어텐션)\n",
        "    attention2 = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "            'query':attention1, 'key' : enc_outputs, 'value': enc_outputs, # Q=K=V\n",
        "            'mask' : padding_mask # 패딩 마스크\n",
        "        })\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(attention2+attention1)\n",
        "\n",
        "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(outputs+ attention2)\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs = outputs,\n",
        "        name= name\n",
        "    )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20EJOE0bCoh4"
      },
      "source": [
        "## 디코더 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qJ_A9gFEHiZ"
      },
      "source": [
        "def decoder(vocab_size, num_layers, dff, d_model, num_heads, dropout, name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs =tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "    #디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩마스크(두번째 서브층) 둘 다 사용\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "        shape = (1, None, None), name='look_ahead_mask')\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "    \n",
        "    #포지셔널 인코딩 + 드롭아웃\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # 디코더를 num_layer개 쌓기\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "                                dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "                                )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "                        \n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs=outputs,\n",
        "        name= name\n",
        "    )"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEXacNVeEs-C"
      },
      "source": [
        "# 합치기\n",
        "def transformer(vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"transformer\"):\n",
        "    #인코더의 입력\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    #디코더의 입력\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    #인코더의 패딩 마스크\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='enc_padding_mask')(inputs)\n",
        "    \n",
        "    #디코더의 룩어헤더 마스크 (첫번째 서브층)\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "        create_look_ahead_mask, output_shape=(1, None, None),\n",
        "        name='look_ahead_mask')(dec_inputs)\n",
        "    \n",
        "    # 디코더의 패딩 마스크 (두번째 서브층)\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name= 'dec_padding_mask'\n",
        "    )(inputs)\n",
        "\n",
        "    # 인코더의 출력은 enc_outputs 디코더로 전달\n",
        "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask]) #인코더의 입력은 입력문장과 패딩마스크\n",
        "\n",
        "    # 디코더의 출력은 dec_outputs 출력층으로 전달\n",
        "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "                            d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "                            )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    # 다음 단어 예측을 위한 출력층\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGM-VyaiErDD"
      },
      "source": [
        "## 트랜스포머 hyperparam 정하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA1E7893O484",
        "outputId": "b2b6a4e6-61ed-42b0-ee8a-2566f253818d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "small_transformer = transformer(\n",
        "    vocab_size = 9000,\n",
        "    num_layers = 4,\n",
        "    dff = 512,\n",
        "    d_model = 128,\n",
        "    num_heads = 4,\n",
        "    dropout = 0.3,\n",
        "    name=\"small_transformer\"\n",
        ")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    small_transformer, to_file='small_transformer.png', show_shapes=True\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 9000, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-54b902a376fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnum_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"small_transformer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-87573b1d3fb2>\u001b[0m in \u001b[0;36mtransformer\u001b[0;34m(vocab_size, num_layers, dff, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# 인코더의 출력은 enc_outputs 디코더로 전달\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     )(inputs=[inputs, enc_padding_mask]) #인코더의 입력은 입력문장과 패딩마스크\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f25c63bedf0d>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(vocab_size, num_layers, dff, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 인코딩를 num_layer개 쌓기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     output = control_flow_util.smart_cond(training, dropped_inputs,\n\u001b[0;32m--> 231\u001b[0;31m                                           lambda: array_ops.identity(inputs))\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    108\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    109\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m--> 110\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     output = control_flow_util.smart_cond(training, dropped_inputs,\n\u001b[0;32m--> 231\u001b[0;31m                                           lambda: array_ops.identity(inputs))\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<__main__.PositionalEncoding object at 0x7f5f8e9c9790>) with an unsupported type (<class '__main__.PositionalEncoding'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neaJHPPKPiNj"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH -1))\n",
        "\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(y_true, y_pred)\n",
        "    mask = tf.cast(tf.not_eual(y_true, 0), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "    return tf.reduce_mean(loss)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww9-tlF-RPsd"
      },
      "source": [
        "$$ lr = d_{model}^{-0.5} \\times  min(step_num^{-0.5}, step-num \\times warmup-steps^{-1.5})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqrj6OHDRJei"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model)* tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwY24cqISjDs",
        "outputId": "bc22c082-e420-4c54-d200-2a392a45d389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOlQJhyFSj7a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}