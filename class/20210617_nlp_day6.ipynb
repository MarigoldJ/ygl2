{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "202106017_nlp_day6.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarigoldJ/ygl2/blob/main/class/20210617_nlp_day6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wV_TzhwXhMo"
      },
      "source": [
        "# Today's Topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIMJCCXJXkFb"
      },
      "source": [
        "*  어제는 단어 단위, 오늘은 글자 단위로 모델에 넣어서 예측해볼 것!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qu01XhFYBUL"
      },
      "source": [
        "# 글자 단위 RNN 언어 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlwcqoujpP6z"
      },
      "source": [
        "![r](https://wikidocs.net/images/page/48649/char_rnn1.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXrXm5f1RVLV"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8_IxCzVXplZ",
        "outputId": "e30556ff-0499-4fdc-c7c9-701b7257da0b"
      },
      "source": [
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('11-0.txt', <http.client.HTTPMessage at 0x7f1e5d9f9f10>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75bhKi_IYPf9"
      },
      "source": [
        "f = open('11-0.txt', 'rb')\n",
        "lines = []\n",
        "for line in f:\n",
        "    line = line.strip().lower().decode('ascii', 'ignore')\n",
        "    if len(line) > 0:\n",
        "        lines.append(line)\n",
        "f.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrFojPfxYcNf",
        "outputId": "f2adf80b-0e73-46c5-a99c-ab0009c87e3b"
      },
      "source": [
        "lines[:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_IfhJjmYs6a",
        "outputId": "f4bc8f6a-1508-423e-938b-8d836049ad41"
      },
      "source": [
        "text = ' '.join(lines)\n",
        "print('문자열의 길이 또는 총 글자의 개수 :', len(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자열의 길이 또는 총 글자의 개수 : 159484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tDPQBeRZAh2",
        "outputId": "c5ad3793-3d43-45fb-b03f-7aa90ccb1376"
      },
      "source": [
        "print(text[:10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the projec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLhgKunOZB5t",
        "outputId": "37522721-18d7-44c5-88e0-b365a95a9cb6"
      },
      "source": [
        "# 글자 집합을 만들어보자\n",
        "char_vocab = sorted(list(set(text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('글자 집합의 크기 :', vocab_size)\n",
        "print(char_vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 56\n",
            "[' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR-v2TNoZSNY",
        "outputId": "c54dac0d-b931-461f-9a4b-5ec2b9ea72b0"
      },
      "source": [
        "# 글자 집합에 인덱스를 부여하고 전부 출력하기\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BczTDMcBZ1qU",
        "outputId": "8051b550-ada1-4391-f636-4ba42d1ce785"
      },
      "source": [
        "# 인덱스로부터 글자를 리턴하기\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key\n",
        "print(index_to_char)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '[', 28: ']', 29: '_', 30: 'a', 31: 'b', 32: 'c', 33: 'd', 34: 'e', 35: 'f', 36: 'g', 37: 'h', 38: 'i', 39: 'j', 40: 'k', 41: 'l', 42: 'm', 43: 'n', 44: 'o', 45: 'p', 46: 'q', 47: 'r', 48: 's', 49: 't', 50: 'u', 51: 'v', 52: 'w', 53: 'x', 54: 'y', 55: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BCIDmAnadvt"
      },
      "source": [
        "# 훈련데이터를 구성\n",
        "# apple\n",
        "# sample의 길이 4\n",
        "\n",
        "# example) 샘플의 길이가 4라면 4개의 입력 글자 시퀀스로부터 4개의 출력 글자 시퀀스 예측. 즉 RNN의 time step은 4번\n",
        "# appl -> pple\n",
        "# appl : 입력시퀀스, train_x\n",
        "# pple : 예측시퀀스, train_y\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G1AyuehbAHx",
        "outputId": "0e4346d9-43aa-4973-d657-8486d7bee728"
      },
      "source": [
        "# 15만 8천의 길이를 가진 text 문자열로부터 다수의 문장 샘플들로 분리\n",
        "# 분리하는 방법은 문장 샘플의 길이를 정하고, 해당 길이만큼 문자열 전부를 전부 등분하는 것!\n",
        "\n",
        "seq_length = 60\n",
        "n_samples = int(np.floor( (len(text)-1) / seq_length )) # 문자열을 60등분한다 --> 총 샘플의 수\n",
        "print('문자 샘플의 수 :', n_samples)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자 샘플의 수 : 2658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d9067VqbYX_"
      },
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "    x_sample = text[i * seq_length: (i+1)*seq_length]       # 문장 샘플을 1개씩 가져옴\n",
        "    x_encoded = [char_to_index[c] for c in x_sample]        # 하나의 문장 샘플에 대해 encoding\n",
        "    train_x.append(x_encoded)\n",
        "\n",
        "    y_sample = text[i*seq_length + 1: (i+1)*seq_length + 1] # x보다 한칸 오른쪽으로 shift\n",
        "    y_encoded = [char_to_index[c] for c in y_sample]\n",
        "    train_y.append(y_encoded)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R9pSgcJbbYG",
        "outputId": "7147d121-5cd5-4960-f268-8d6bce4c6371"
      },
      "source": [
        "print(train_x[0])\n",
        "print(train_y[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
            "[37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEIX4oFWcmeg",
        "outputId": "4734256d-57a1-4dc5-fe7c-226bd82a58b3"
      },
      "source": [
        "# x와 y에 대해 원-핫 인코딩 수행\n",
        "# 입력시퀀스에 대해 워드 임베딩 하지 않습니다 (embedding layer 사용 X)\n",
        "train_x = to_categorical(train_x)\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "print('train_x의 크기 (shape) :', train_x.shape)    # (2658, 60, 56)\n",
        "print('train_y의 크기 (shape) :', train_y.shape)    # (2658, 60, 56)\n",
        "\n",
        "# 샘플의 수 : 2658\n",
        "# 입력시퀀스 길이(input_length) : 60\n",
        "# 각 벡터의 차원(input_dim) : 56\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x의 크기 (shape) : (2658, 60, 56)\n",
            "train_y의 크기 (shape) : (2658, 60, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i-3qTpHpMZD"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22886/rnn_image6between7.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_UiClJmiz4r"
      },
      "source": [
        "## 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vhuWaKhiRZN"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_RAPLZdjd92"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(None, train_x.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zke4LuyIj1qQ",
        "outputId": "42d77aae-8a74-4948-ad81-5d5309e0ed32"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, epochs=80, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "84/84 [==============================] - 6s 12ms/step - loss: 3.0811 - accuracy: 0.1801\n",
            "Epoch 2/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.7441 - accuracy: 0.2436\n",
            "Epoch 3/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3913 - accuracy: 0.3291\n",
            "Epoch 4/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.2314 - accuracy: 0.3674\n",
            "Epoch 5/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.1205 - accuracy: 0.3925\n",
            "Epoch 6/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.0284 - accuracy: 0.4161\n",
            "Epoch 7/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.9524 - accuracy: 0.4370\n",
            "Epoch 8/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.8891 - accuracy: 0.4530\n",
            "Epoch 9/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.8332 - accuracy: 0.4680\n",
            "Epoch 10/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.7790 - accuracy: 0.4840\n",
            "Epoch 11/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.7323 - accuracy: 0.4961\n",
            "Epoch 12/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.6928 - accuracy: 0.5054\n",
            "Epoch 13/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.6517 - accuracy: 0.5167\n",
            "Epoch 14/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.6153 - accuracy: 0.5269\n",
            "Epoch 15/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5783 - accuracy: 0.5366\n",
            "Epoch 16/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5452 - accuracy: 0.5447\n",
            "Epoch 17/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5107 - accuracy: 0.5544\n",
            "Epoch 18/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4810 - accuracy: 0.5619\n",
            "Epoch 19/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4513 - accuracy: 0.5693\n",
            "Epoch 20/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4195 - accuracy: 0.5789\n",
            "Epoch 21/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3908 - accuracy: 0.5873\n",
            "Epoch 22/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3668 - accuracy: 0.5936\n",
            "Epoch 23/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3357 - accuracy: 0.6031\n",
            "Epoch 24/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3058 - accuracy: 0.6110\n",
            "Epoch 25/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2772 - accuracy: 0.6189\n",
            "Epoch 26/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2482 - accuracy: 0.6274\n",
            "Epoch 27/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2242 - accuracy: 0.6339\n",
            "Epoch 28/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1952 - accuracy: 0.6422\n",
            "Epoch 29/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1645 - accuracy: 0.6523\n",
            "Epoch 30/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1391 - accuracy: 0.6598\n",
            "Epoch 31/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1072 - accuracy: 0.6694\n",
            "Epoch 32/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0815 - accuracy: 0.6763\n",
            "Epoch 33/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0514 - accuracy: 0.6858\n",
            "Epoch 34/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0199 - accuracy: 0.6951\n",
            "Epoch 35/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9939 - accuracy: 0.7031\n",
            "Epoch 36/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9663 - accuracy: 0.7120\n",
            "Epoch 37/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9368 - accuracy: 0.7204\n",
            "Epoch 38/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9153 - accuracy: 0.7274\n",
            "Epoch 39/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8924 - accuracy: 0.7341\n",
            "Epoch 40/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8580 - accuracy: 0.7461\n",
            "Epoch 41/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8302 - accuracy: 0.7540\n",
            "Epoch 42/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8026 - accuracy: 0.7633\n",
            "Epoch 43/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7737 - accuracy: 0.7726\n",
            "Epoch 44/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7481 - accuracy: 0.7802\n",
            "Epoch 45/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7244 - accuracy: 0.7874\n",
            "Epoch 46/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7087 - accuracy: 0.7918\n",
            "Epoch 47/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6783 - accuracy: 0.8018\n",
            "Epoch 48/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6542 - accuracy: 0.8097\n",
            "Epoch 49/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6304 - accuracy: 0.8167\n",
            "Epoch 50/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6142 - accuracy: 0.8218\n",
            "Epoch 51/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5913 - accuracy: 0.8300\n",
            "Epoch 52/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5754 - accuracy: 0.8342\n",
            "Epoch 53/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5370 - accuracy: 0.8475\n",
            "Epoch 54/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5284 - accuracy: 0.8504\n",
            "Epoch 55/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5046 - accuracy: 0.8576\n",
            "Epoch 56/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4817 - accuracy: 0.8660\n",
            "Epoch 57/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4611 - accuracy: 0.8730\n",
            "Epoch 58/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4491 - accuracy: 0.8761\n",
            "Epoch 59/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4329 - accuracy: 0.8809\n",
            "Epoch 60/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4118 - accuracy: 0.8882\n",
            "Epoch 61/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3893 - accuracy: 0.8951\n",
            "Epoch 62/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3962 - accuracy: 0.8916\n",
            "Epoch 63/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3687 - accuracy: 0.9014\n",
            "Epoch 64/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3486 - accuracy: 0.9090\n",
            "Epoch 65/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3371 - accuracy: 0.9120\n",
            "Epoch 66/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3159 - accuracy: 0.9198\n",
            "Epoch 67/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3109 - accuracy: 0.9195\n",
            "Epoch 68/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2987 - accuracy: 0.9236\n",
            "Epoch 69/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2996 - accuracy: 0.9215\n",
            "Epoch 70/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3127 - accuracy: 0.9145\n",
            "Epoch 71/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2787 - accuracy: 0.9280\n",
            "Epoch 72/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2636 - accuracy: 0.9336\n",
            "Epoch 73/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2480 - accuracy: 0.9386\n",
            "Epoch 74/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2237 - accuracy: 0.9472\n",
            "Epoch 75/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2163 - accuracy: 0.9488\n",
            "Epoch 76/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2020 - accuracy: 0.9530\n",
            "Epoch 77/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2124 - accuracy: 0.9489\n",
            "Epoch 78/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2112 - accuracy: 0.9480\n",
            "Epoch 79/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2028 - accuracy: 0.9508\n",
            "Epoch 80/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2026 - accuracy: 0.9498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e102bd190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o9k2gnqj9vH"
      },
      "source": [
        "def sentence_generation(model, length):\n",
        "\n",
        "    ix = [np.random.randint(vocab_size)]        # 글자에 대한 랜덤 인덱스 생성\n",
        "    y_char = [index_to_char[ix[-1]]]            # 랜덤 인덱스로부터 글자 생성\n",
        "    print(ix[-1], '번 글자', y_char[-1], '로 예측을 시작!!')\n",
        "    \n",
        "    X = np.zeros((1, length, vocab_size))       # LSTM의 입력 시퀀스 생성\n",
        "\n",
        "    for i in range(length):\n",
        "        X[0][i][ix[-1]] = 1                     # 예측 글자를 다음 입력 시퀀스에 추가\n",
        "        print(index_to_char[ix[-1]], end='')\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    \n",
        "    return ('').join(y_char)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "6g-S5CRUoUPy",
        "outputId": "808cb441-b92f-4a3c-aee0-567f298ddc6f"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 번 글자   로 예측을 시작!!\n",
            " and then said the fourth. two days wrong! sighed the hatter. i dene read: it mest question is, you "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' and then said the fourth. two days wrong! sighed the hatter. i dene read: it mest question is, you d'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "fCQyp0BAoY88",
        "outputId": "87518198-c171-49a5-e879-dd1e5901b2f5"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41 번 글자 l 로 예측을 시작!!\n",
            "ll her knowledge of history, alice had no very clear notion here! _you do not agree to abide a pie o"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ll her knowledge of history, alice had no very clear notion here! _you do not agree to abide a pie of'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_osiG_mtdsh"
      },
      "source": [
        "# 글자 단위 RNN(Char RNN)으로 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlGIL9FRtgoI"
      },
      "source": [
        "* 다 대 일(many-to-one)구조의 RNN을 글자 단위로 학습시키고, 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZqjVn8btm8k"
      },
      "source": [
        "## 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LG-tQWSpzWX"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3dV6AICtuPV"
      },
      "source": [
        "text='''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf7fQ4O9uKxZ",
        "outputId": "5f10a882-17df-43a5-ed21-98f1e23615f4"
      },
      "source": [
        "tokens = text.split()       # \\n 제거\n",
        "text = ' '.join(tokens)\n",
        "\n",
        "print(text)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bimC38ObuQ7_",
        "outputId": "3c12a419-f1e1-40e8-ff48-675cbb1ba03e"
      },
      "source": [
        "# 중복 제거한 글자 집합 생성\n",
        "char_vocab = sorted(list(set(text)))\n",
        "\n",
        "print(char_vocab)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieIyCEunus2i",
        "outputId": "cdef00ff-b236-46e4-c6d7-fd777e169652"
      },
      "source": [
        "# 글자 집합의 크기\n",
        "vocab_size = len(char_vocab)\n",
        "\n",
        "print('글자 집합의 크기 :', vocab_size)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnqSGDzcuwtZ",
        "outputId": "371ed823-8c89-4334-d662-f749266307d2"
      },
      "source": [
        "# 글자에 고유한 정수 인덱스 부여\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "\n",
        "print(char_to_index)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJHzyP0YvGld"
      },
      "source": [
        "* example 5개의 입력 글자 시퀀스로부터 다음 글자 시퀀스를 예측\n",
        "    * stude -> n\n",
        "    * tuden -> t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHeGY553u1WG",
        "outputId": "e304b2cb-2ed4-4be7-9490-a968466688d8"
      },
      "source": [
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(text)):\n",
        "    seq = text[i-length:i]  # 길이 11의 문자열을 지속적으로 만듦\n",
        "    sequences.append(seq)\n",
        "\n",
        "print('총 훈련 샘플의 수 :', len(sequences))\n",
        "print(sequences)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 훈련 샘플의 수 : 426\n",
            "['I get on wi', ' get on wit', 'get on with', 'et on with ', 't on with l', ' on with li', 'on with lif', 'n with life', ' with life ', 'with life a', 'ith life as', 'th life as ', 'h life as a', ' life as a ', 'life as a p', 'ife as a pr', 'fe as a pro', 'e as a prog', ' as a progr', 'as a progra', 's a program', ' a programm', 'a programme', ' programmer', 'programmer,', 'rogrammer, ', 'ogrammer, I', 'grammer, I ', 'rammer, I l', 'ammer, I li', 'mmer, I lik', 'mer, I like', 'er, I like ', 'r, I like t', ', I like to', ' I like to ', 'I like to c', ' like to co', 'like to con', 'ike to cont', 'ke to conte', 'e to contem', ' to contemp', 'to contempl', 'o contempla', ' contemplat', 'contemplate', 'ontemplate ', 'ntemplate b', 'template be', 'emplate bee', 'mplate beer', 'plate beer.', 'late beer. ', 'ate beer. B', 'te beer. Bu', 'e beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sta', 'when I star', 'hen I start', 'en I start ', 'n I start t', ' I start to', 'I start to ', ' start to d', 'start to da', 'tart to day', 'art to dayd', 'rt to daydr', 't to daydre', ' to daydrea', 'to daydream', 'o daydream,', ' daydream, ', 'daydream, M', 'aydream, My', 'ydream, My ', 'dream, My m', 'ream, My mi', 'eam, My min', 'am, My mind', 'm, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. D', 'to wine. Do', 'o wine. Do ', ' wine. Do I', 'wine. Do I ', 'ine. Do I l', 'ne. Do I lo', 'e. Do I lov', '. Do I love', ' Do I love ', 'Do I love w', 'o I love wi', ' I love win', 'I love wine', ' love wine ', 'love wine m', 'ove wine mo', 've wine mor', 'e wine more', ' wine more ', 'wine more t', 'ine more th', 'ne more tha', 'e more than', ' more than ', 'more than b', 'ore than be', 're than bee', 'e than beer', ' than beer?', 'than beer? ', 'han beer? I', 'an beer? I ', 'n beer? I l', ' beer? I li', 'beer? I lik', 'eer? I like', 'er? I like ', 'r? I like t', '? I like to', ' I like to ', 'I like to u', ' like to us', 'like to use', 'ike to use ', 'ke to use w', 'e to use wo', ' to use wor', 'to use word', 'o use words', ' use words ', 'use words a', 'se words ab', 'e words abo', ' words abou', 'words about', 'ords about ', 'rds about b', 'ds about be', 's about bee', ' about beer', 'about beer.', 'bout beer. ', 'out beer. B', 'ut beer. Bu', 't beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sto', 'when I stop', 'hen I stop ', 'en I stop m', 'n I stop my', ' I stop my ', 'I stop my t', ' stop my ta', 'stop my tal', 'top my talk', 'op my talki', 'p my talkin', ' my talking', 'my talking,', 'y talking, ', ' talking, M', 'talking, My', 'alking, My ', 'lking, My m', 'king, My mi', 'ing, My min', 'ng, My mind', 'g, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. I', 'to wine. I ', 'o wine. I h', ' wine. I ha', 'wine. I hat', 'ine. I hate', 'ne. I hate ', 'e. I hate b', '. I hate bu', ' I hate bug', 'I hate bugs', ' hate bugs ', 'hate bugs a', 'ate bugs an', 'te bugs and', 'e bugs and ', ' bugs and e', 'bugs and er', 'ugs and err', 'gs and erro', 's and error', ' and errors', 'and errors.', 'nd errors. ', 'd errors. B', ' errors. Bu', 'errors. But', 'rrors. But ', 'rors. But I', 'ors. But I ', 'rs. But I j', 's. But I ju', '. But I jus', ' But I just', 'But I just ', 'ut I just t', 't I just th', ' I just thi', 'I just thin', ' just think', 'just think ', 'ust think b', 'st think ba', 't think bac', ' think back', 'think back ', 'hink back t', 'ink back to', 'nk back to ', 'k back to w', ' back to wi', 'back to win', 'ack to wine', 'ck to wine,', 'k to wine, ', ' to wine, A', 'to wine, An', 'o wine, And', ' wine, And ', 'wine, And I', \"ine, And I'\", \"ne, And I'm\", \"e, And I'm \", \", And I'm h\", \" And I'm ha\", \"And I'm hap\", \"nd I'm happ\", \"d I'm happy\", \" I'm happy \", \"I'm happy o\", \"'m happy on\", 'm happy onc', ' happy once', 'happy once ', 'appy once a', 'ppy once ag', 'py once aga', 'y once agai', ' once again', 'once again.', 'nce again. ', 'ce again. I', 'e again. I ', ' again. I l', 'again. I li', 'gain. I lik', 'ain. I like', 'in. I like ', 'n. I like t', '. I like to', ' I like to ', 'I like to h', ' like to ha', 'like to han', 'ike to hang', 'ke to hang ', 'e to hang o', ' to hang ou', 'to hang out', 'o hang out ', ' hang out w', 'hang out wi', 'ang out wit', 'ng out with', 'g out with ', ' out with p', 'out with pr', 'ut with pro', 't with prog', ' with progr', 'with progra', 'ith program', 'th programm', 'h programmi', ' programmin', 'programming', 'rogramming ', 'ogramming a', 'gramming an', 'ramming and', 'amming and ', 'mming and d', 'ming and de', 'ing and dee', 'ng and deep', 'g and deep ', ' and deep l', 'and deep le', 'nd deep lea', 'd deep lear', ' deep learn', 'deep learni', 'eep learnin', 'ep learning', 'p learning.', ' learning. ', 'learning. B', 'earning. Bu', 'arning. But', 'rning. But ', 'ning. But w', 'ing. But wh', 'ng. But whe', 'g. But when', '. But when ', ' But when l', 'But when le', 'ut when lef', 't when left', ' when left ', 'when left a', 'hen left al', 'en left alo', 'n left alon', ' left alone', 'left alone,', 'eft alone, ', 'ft alone, M', 't alone, My', ' alone, My ', 'alone, My m', 'lone, My mi', 'one, My min', 'ne, My mind', 'e, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2nVgH9zvydA",
        "outputId": "e529cb3e-c6c1-421f-e313-7f81417b66a0"
      },
      "source": [
        "# sequences에 있는 문장들의 글자들을 index로 변환\n",
        "x = []\n",
        "for line in sequences:\n",
        "    temp_x = [char_to_index[char] for char in line]\n",
        "    x.append(temp_x)\n",
        "\n",
        "# 결과 확인\n",
        "for line in x[:5]:\n",
        "    print(line)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18]\n",
            "[0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28]\n",
            "[16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17]\n",
            "[14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0]\n",
            "[28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Mu2GeewHge",
        "outputId": "057463ae-6a59-4106-c53f-b8ddc584363e"
      },
      "source": [
        "sequences = np.array(x)\n",
        "x = sequences[:, :-1]\n",
        "y = sequences[:, -1] # 맨 마지막 위치의 글자를 분리\n",
        "\n",
        "for line in x[:5]:\n",
        "    print(line)\n",
        "\n",
        "print()\n",
        "print(y[:5])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8  0 16 14 28  0 24 23  0 31]\n",
            "[ 0 16 14 28  0 24 23  0 31 18]\n",
            "[16 14 28  0 24 23  0 31 18 28]\n",
            "[14 28  0 24 23  0 31 18 28 17]\n",
            "[28  0 24 23  0 31 18 28 17  0]\n",
            "\n",
            "[18 28 17  0 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1cuqGdVw1wt"
      },
      "source": [
        "sequences = [to_categorical(x_, num_classes=vocab_size) for x_ in x]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtIMpkmYxKRe"
      },
      "source": [
        "x = np.array(sequences)\n",
        "y = to_categorical(y, num_classes=vocab_size)   # y에 대한 원-핫 인코딩"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUeXPsovxQHY",
        "outputId": "444081cf-8d4c-464a-8901-8fbd69bd46a9"
      },
      "source": [
        "print(x.shape)\n",
        "\n",
        "# 샘플 수 426\n",
        "# 입력시퀀스 길이 10\n",
        "# 입력 벡터 차원 33"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 10, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoJORIlBynPW"
      },
      "source": [
        "## 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fM1dODNxRU6"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPn115wsy0Lj"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=x.shape[1:]))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj3NCRJzzH3j",
        "outputId": "9f2e328f-7907-4d29-dd62-1553e76537e7"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=100, verbose=1)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 3.4541 - accuracy: 0.1502\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 3.1992 - accuracy: 0.1972\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.9903 - accuracy: 0.1972\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.9660 - accuracy: 0.1972\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.9234 - accuracy: 0.1972\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.9003 - accuracy: 0.1972\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.8703 - accuracy: 0.1972\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.8469 - accuracy: 0.2042\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.7880 - accuracy: 0.1995\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.7279 - accuracy: 0.2230\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.6722 - accuracy: 0.2277\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.6096 - accuracy: 0.2606\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.5289 - accuracy: 0.2770\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.4661 - accuracy: 0.2887\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.3758 - accuracy: 0.3099\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.3379 - accuracy: 0.3404\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.2471 - accuracy: 0.3521\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.1855 - accuracy: 0.3592\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.0769 - accuracy: 0.3967\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.0090 - accuracy: 0.4131\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.9268 - accuracy: 0.4249\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.8768 - accuracy: 0.4296\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.8113 - accuracy: 0.4953\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.7411 - accuracy: 0.4789\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.6573 - accuracy: 0.5376\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.6058 - accuracy: 0.5211\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.5093 - accuracy: 0.5798\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.4470 - accuracy: 0.6103\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.4074 - accuracy: 0.6080\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.3207 - accuracy: 0.6761\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.2596 - accuracy: 0.6573\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.1912 - accuracy: 0.7160\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.1303 - accuracy: 0.7113\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.0869 - accuracy: 0.7394\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.0318 - accuracy: 0.7653\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.7723\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.9711 - accuracy: 0.7629\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.8738 - accuracy: 0.8028\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.8207 - accuracy: 0.8005\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.7506 - accuracy: 0.8357\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.8521\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.8803\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.8756\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.8873\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.8967\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.9249\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.9155\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.9366\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.9484\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.9577\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.9507\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.9648\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9648\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.9765\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.9789\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.9695\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.9742\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9765\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9789\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9859\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9789\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9765\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9742\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9812\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9789\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9812\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9789\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9812\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9765\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9789\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9812\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9859\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9765\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9812\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9718\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9789\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9859\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9765\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9836\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9859\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9812\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9836\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9859\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9859\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9812\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9765\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9765\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9789\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9718\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9812\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9836\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9765\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9812\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9836\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9812\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9812\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9836\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9836\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9836\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1d8573b5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLegXGIdzgPk"
      },
      "source": [
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "    # 모델, 인덱스 정보, 문장길이, 초기 시퀀스, 반복횟수\n",
        "\n",
        "    init_text = seed_text   # 문장 생성에 사용할 초기 시퀀스\n",
        "    sentence = ''\n",
        "\n",
        "    for _ in range(n):\n",
        "        # 현재 시퀀스에 대한 정수 인코딩\n",
        "        encoded = [char_to_index[char] for char in seed_text]\n",
        "\n",
        "        # 데이터에 대한 패딩\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')\n",
        "\n",
        "        # \n",
        "        encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "\n",
        "        # 입력한 x(현재 시퀀스)에 대해서 y(예측한 글자)를 예측하고 저장\n",
        "        result = model.predict_classes(encoded, verbose=0)\n",
        "\n",
        "        for char, index in char_to_index.items():\n",
        "            if index == result: # 만약 예측 글자와 인덱스가 동일한 글자가 있으면\n",
        "                break           # 해당 글자가 예측 글자이므로 break\n",
        "\n",
        "        seed_text = seed_text + char    # 현재 시퀀스에 예측글자 추가\n",
        "        sentence = sentence + char      # 예측 글자를 문장에 저장\n",
        "    \n",
        "    sentence = init_text + sentence\n",
        "\n",
        "    return sentence\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MVH3xm91T8E",
        "outputId": "bb02b9f5-1f15-49b6-b21e-656456bf4df8"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'I got on w', 100))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I got on with life as a programmer, I like to use words about beer. But when I stort to toddrerm.m..But lnnne \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZXrbBIxW2-Y"
      },
      "source": [
        "# 네이버 쇼핑 리뷰 감성 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zal9K3tgXJTZ"
      },
      "source": [
        "* 총 200,000개 리뷰로 구성됨\n",
        "* 평점이 5점 만점에 1, 2, 4, 5인 리뷰들로 구성\n",
        "* 평점이 4, 5인 리뷰들에 긍정1, 부정0\n",
        "* 감성 분류 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXJvg0LF1YuW",
        "outputId": "b73c6094-f68a-47ea-899d-70d838cae3a3"
      },
      "source": [
        "# Mecab 설치\n",
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TcoUP_OXgw-",
        "outputId": "ac674e36-9a21-4acd-f2d7-e9730c5c6fe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! bash Mecab-ko-for-Google-Colab/install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 71.1MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 28.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-06-17 05:09:14--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c3:9b0a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=VxU26vc9FV3JNOomuRLBhcbAMDs%3D&Expires=1623907534&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 05:09:14--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=VxU26vc9FV3JNOomuRLBhcbAMDs%3D&Expires=1623907534&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.105.211\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.105.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.64MB/s    in 0.5s    \n",
            "\n",
            "2021-06-17 05:09:15 (2.64 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-06-17 05:10:28--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2B7bEmbHCl21WZ2PCLLhxUw7Khz4%3D&Expires=1623907603&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 05:10:29--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2B7bEmbHCl21WZ2PCLLhxUw7Khz4%3D&Expires=1623907603&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.145.75\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.145.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  23.0MB/s    in 2.1s    \n",
            "\n",
            "2021-06-17 05:10:31 (23.0 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKJreb-X32Y",
        "outputId": "f04c8b01-1f55-4e8e-bf57-1d7f97861d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "print(mecab.morphs('이미 아무것도 하지 않고 있지만 더 격렬하고 적극적으로 아무것도 하기 싫다.'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이미', '아무것', '도', '하', '지', '않', '고', '있', '지만', '더', '격렬', '하', '고', '적극', '적', '으로', '아무것', '도', '하', '기', '싫', '다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wm8RdmIYxnI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a1_gVR8a08e",
        "outputId": "80db8a65-00cc-4e98-92ed-d04d24fb55cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_total.txt', <http.client.HTTPMessage at 0x7f7c2936d910>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ6E-4qEa5Dj"
      },
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM9vRsz_a6Xh",
        "outputId": "6a0d3d23-f234-4082-9f95-e8b8088e3339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('전체 리뷰 갯수 :', len(total_data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 리뷰 갯수 : 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t40RLUqYa7i3",
        "outputId": "de164397-33d3-42e0-da64-d4722b00f509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "total_data[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews\n",
              "0        5                                            배공빠르고 굿\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_R2UnntbBAd"
      },
      "source": [
        "## 훈련 데이터와 테스트 데이터를 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E106Xldga-Lj",
        "outputId": "5efbcfa2-db3b-4c65-e82f-0137a2107fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)\n",
        "total_data[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews  label\n",
              "0        5                                            배공빠르고 굿      1\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "671qzYk8ba30",
        "outputId": "542026e4-a7b3-4170-dda5-eb428f5fccdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 각 열에 중복을 제외한 샘플의 수를 카운트\n",
        "total_data['ratings'].nunique(), total_data['reviews'].nunique(), total_data['label'].nunique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 199908, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxFd5DLMbvhG",
        "outputId": "3bb89dd0-cff3-44c7-8f13-b6714501e1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# reviews 열에서 중복된 행 제거\n",
        "total_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "print('총 샘플의 수 :', len(total_data))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 수 : 199908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSO2WasVb2GV",
        "outputId": "d37d9479-ebfa-417b-d838-2629fe849693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Null 값 유무\n",
        "print(total_data.isnull().sum())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratings    0\n",
            "reviews    0\n",
            "label      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VohFPt4ZcBGl",
        "outputId": "6f60f915-8271-4930-a2ce-6b4be10724ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train 데이터와 test 데이터를 3:1 비율로 나눔\n",
        "train_data, test_data = train_test_split(total_data, test_size=0.25, random_state=42)\n",
        "print('훈련용 리뷰의 개수 :', len(train_data))\n",
        "print('테스트용 리뷰의 개수 :', len(test_data))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 리뷰의 개수 : 149931\n",
            "테스트용 리뷰의 개수 : 49977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqpjJqmlcovq"
      },
      "source": [
        "## 레이블의 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsUb8TgPcI5v",
        "outputId": "2aa35ede-f0b8-40ef-a2cb-36be2c253fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "train_data['label'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7bea071850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIHoCnQVcq9a",
        "outputId": "205179a6-aad4-449c-8410-1bbecc74b925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_data.groupby('label').size().reset_index(name='count'))\n",
        "# 거의 1:1 비율로 가져온 것을 확인할 수 있다."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  count\n",
            "0      0  74918\n",
            "1      1  75013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEnQCRNHc09J"
      },
      "source": [
        "## 데이터 정제하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0SaiSkHc22G"
      },
      "source": [
        "* 정규 표현식을 활용하여 한글을 제외하고 모두 제거하기\n",
        "* 빈 샘플이 생겼는지 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30FGQlL9eLYh"
      },
      "source": [
        "# 경고문 삭제\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTzt9sjLcu0Y",
        "outputId": "7cbbf096-8dc3-4316-c825-485920c5892a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data['reviews'] = train_data['reviews'].str.replace('[^ㄱ-ㅣ가-힣]', '')\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())\n",
        "print('전처리 후 훈련용 샘플의 개수 :', len(train_data))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratings    0\n",
            "reviews    0\n",
            "label      0\n",
            "dtype: int64\n",
            "전처리 후 훈련용 샘플의 개수 : 149931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sJSV4IUdLAG",
        "outputId": "19801d12-71e1-4d93-a780-5e8b46aab947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\"\")\n",
        "test_data['reviews'].replace('', np.nan, inplace=True)\n",
        "test_data = test_data.dropna(how='any')\n",
        "print('전처리 후 테스트용 샘플의 갯수 : ',len(test_data))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전처리 후 테스트용 샘플의 갯수 :  49923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-KnJWcsd1CC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow0pVv9Hd5aB"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7oMHMKFd6k_"
      },
      "source": [
        "mecab = Mecab()\n",
        "\n",
        "# 불용어\n",
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktSHpGsdeWyb"
      },
      "source": [
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEh1a_EUel1e"
      },
      "source": [
        "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SUbjttJfGWj"
      },
      "source": [
        "## 단어의 길이 분포 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWISBZI4etKG"
      },
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
        "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sG0mtekf9ht",
        "outputId": "84714c73-b2fb-47d8-d5fd-f2f65a6682b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 부정 리뷰에 대해서 빈도수가 높은 상위 20개 단어 출력.\n",
        "# Counter()를 사용하여 각 단어에 대한 빈도수 계산\n",
        "negative_word_count = Counter(negative_words)\n",
        "positive_word_count = Counter(positive_words)\n",
        "\n",
        "print('부정리뷰 상위 20개')\n",
        "print(negative_word_count.most_common(20))\n",
        "print()\n",
        "print('긍정리뷰 상위 20개')\n",
        "print(positive_word_count.most_common(20))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "부정리뷰 상위 20개\n",
            "[('네요', 29687), ('는데', 19748), ('안', 18779), ('어요', 13799), ('있', 12927), ('너무', 12576), ('했', 11492), ('좋', 9463), ('배송', 9452), ('어', 8929), ('같', 8631), ('구매', 8540), ('거', 8379), ('없', 8264), ('습니다', 8209), ('되', 8130), ('아요', 8054), ('그냥', 7927), ('않', 7757), ('잘', 7576)]\n",
            "\n",
            "긍정리뷰 상위 20개\n",
            "[('좋', 38612), ('아요', 20203), ('네요', 18965), ('잘', 18036), ('어요', 17891), ('구매', 15799), ('습니다', 13113), ('있', 12211), ('배송', 11939), ('는데', 11436), ('했', 9645), ('합니다', 9553), ('먹', 9457), ('재', 9064), ('너무', 8148), ('같', 7640), ('만족', 7071), ('어', 6628), ('아', 6531), ('거', 6261)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_-jDJzhgTgw",
        "outputId": "a1ad6e41-85ea-4fc7-eb57-a6eee89d544f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "text_len1 = train_data[train_data.label == 1]['tokenized'].map(lambda x: len(x))\n",
        "ax1.hist(text_len1, color='red')\n",
        "ax1.set_title('Positive Reviews')\n",
        "ax1.set_xlabel('length of samples')\n",
        "ax1.set_ylabel('number of samples')\n",
        "\n",
        "text_len2 = train_data[train_data.label == 0]['tokenized'].map(lambda x: len(x))\n",
        "ax2.hist(text_len2, color='blue')\n",
        "ax2.set_title('Negative Reviews')\n",
        "ax2.set_xlabel('length of samples')\n",
        "ax2.set_ylabel('number of samples')\n",
        "\n",
        "print('긍정 리뷰의 평균 길이 :', np.mean(text_len1))\n",
        "print('부정 리뷰의 평균 길이 :', np.mean(text_len2))\n",
        "\n",
        "# 부정 리뷰의 길이가 좀더 길군..."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "긍정 리뷰의 평균 길이 : 13.229400237292202\n",
            "부정 리뷰의 평균 길이 : 16.35456098667877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDey_4_RhdtJ"
      },
      "source": [
        "x_train = train_data['tokenized'].values\n",
        "y_train = train_data['label'].values\n",
        "x_test = test_data['tokenized'].values\n",
        "y_test = test_data['label'].values"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08kD6Riis0w"
      },
      "source": [
        "## 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhB3BozOih55"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ba8HX9JiwAM",
        "outputId": "66e41689-3456-41c5-ac42-f4428eead066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "threshold = 2\n",
        "total_cnt = len(t.word_index)   # 단어의 수\n",
        "rare_cnt = 0\n",
        "total_freq = 0\n",
        "rare_freq = 0\n",
        "\n",
        "# 단어의 빈도수의 쌍을 key와 value로 받는다.\n",
        "for key, value in t.word_counts.items():\n",
        "    total_freq += value\n",
        "\n",
        "    if (value < threshold):\n",
        "        rare_cnt += 1\n",
        "        rare_freq += value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print(f'등장 빈도가 {threshold}번 이하인 희귀 단어의 수 :', rare_cnt)\n",
        "print('단어 집합에서 희귀 단어의 비율 :', (rare_cnt/total_cnt)*100, '%')\n",
        "print('전체 등장 빈도에서 희귀 단어 등장 빈도 비율 :', (rare_freq/total_freq)*100, '%')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 51331\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수 : 27839\n",
            "단어 집합에서 희귀 단어의 비율 : 54.23428337651711 %\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율 : 1.255350311233444 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWZdeOR6j9lf",
        "outputId": "9ff602ba-c7b7-4171-b0cd-4660aa681a82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 전체 단어 갯수 중 빈도수 2 이하인 단어 개수는 제거\n",
        "# 0번 패딩 토큰과 1번 OOV 토큰을 고려해서 +2\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :', vocab_size)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 23494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xofSFeSpaEC",
        "outputId": "3e877df9-f4c9-4398-d161-c047ba3bec3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "original_vocab_size = vocab_size + rare_cnt - 2\n",
        "print('기존의 단어집합 크기 :', original_vocab_size)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기존의 단어집합 크기 : 51331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJTkPjxcp4IR"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N5lhiMPqboR",
        "outputId": "576fefbd-360a-460c-ba3e-908f362b8878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train[:3])\n",
        "print(x_test[:3])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[64, 2081, 296, 14978, 257, 71, 6, 243, 163, 134, 783, 3060, 626, 2, 1], [457, 408, 50, 8676, 25, 1], [43, 24, 837, 111, 36, 2439, 179, 7, 10, 8171, 4, 1257, 29, 137, 320, 44, 58, 179, 137, 7, 1913, 1996, 109, 162, 1414, 330, 121, 135]]\n",
            "[[14, 690, 749, 112, 187, 246, 12], [334, 3869, 62, 4182, 1633], [11, 68, 2, 48, 156, 3, 27, 15, 6, 555, 285, 16, 90, 108, 589, 58, 7, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU2qFW53sL4C"
      },
      "source": [
        "# 패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXcLwiEXsLGx",
        "outputId": "f9ab8f63-acfb-42e7-ff93-e656ef2737c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "print('리뷰의 최대 길이 :', max(len(l) for l in x_train))\n",
        "print('리뷰의 평균 길이 :', sum(map(len, x_train)) / len(x_train))\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of smaples')\n",
        "plt.ylabel('number of sample')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 85\n",
            "리뷰의 평균 길이 : 14.790990522306927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of sample')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkUvzujBsmZ0"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "    cnt = 0\n",
        "    for s in nested_list:\n",
        "        if(len(s) <= max_len):\n",
        "            cnt += 1\n",
        "    print(f'전체 샘플 중 길이가 {max_len} 이하인 샘플의 비율 : {cnt/len(nested_list) * 100} %')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb5go0drs4Rs",
        "outputId": "7f9e1e92-1f65-432f-bba1-97e06d67756b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_len = 80\n",
        "below_threshold_len(max_len, x_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 80 이하인 샘플의 비율 : 99.99933302652553 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SomnV6xtNJw",
        "outputId": "99eb2ccb-8b68-40f4-cc31-0af22aee3cb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149931, 80)\n",
            "(49923, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4K3XwP-tiMc"
      },
      "source": [
        "## GRU 모델로 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJgO6qAtYAp"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bxPsjgGt0y2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka50nlEmudhJ"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mo = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myyBuP_Aup6R",
        "outputId": "e818c97e-36af-4378-fb01-d8a8b37d0418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history = model.fit(x_train, y_train, epochs=30, callbacks=[es, mo], batch_size=60, validation_split=0.2)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2000/2000 [==============================] - 62s 30ms/step - loss: 0.2815 - acc: 0.8900 - val_loss: 0.2375 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.91170, saving model to best_model.h5\n",
            "Epoch 2/30\n",
            "2000/2000 [==============================] - 59s 29ms/step - loss: 0.2051 - acc: 0.9243 - val_loss: 0.2296 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.91170 to 0.91323, saving model to best_model.h5\n",
            "Epoch 3/30\n",
            "2000/2000 [==============================] - 58s 29ms/step - loss: 0.1685 - acc: 0.9376 - val_loss: 0.2412 - val_acc: 0.9117\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.91323\n",
            "Epoch 4/30\n",
            "2000/2000 [==============================] - 57s 29ms/step - loss: 0.1411 - acc: 0.9480 - val_loss: 0.2640 - val_acc: 0.9071\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.91323\n",
            "Epoch 5/30\n",
            "2000/2000 [==============================] - 58s 29ms/step - loss: 0.1172 - acc: 0.9567 - val_loss: 0.2984 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.91323\n",
            "Epoch 6/30\n",
            "2000/2000 [==============================] - 57s 29ms/step - loss: 0.0986 - acc: 0.9626 - val_loss: 0.3568 - val_acc: 0.9023\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.91323\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Y28ttgyP4G",
        "outputId": "1241eeb1-8759-4c32-8205-4a77f799dc11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 저장된 모델 불러오기\n",
        "loaded_model = load_model('best_model.h5')\n",
        "# loaded_model = model\n",
        "print(f'\\n 테스트 정확도 : {loaded_model.evaluate(x_test, y_test)[1]:.4f}')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1561/1561 [==============================] - 6s 4ms/step - loss: 0.2226 - acc: 0.9200\n",
            "\n",
            " 테스트 정확도 : 0.9200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNrLhdBQyM7s"
      },
      "source": [
        "## 리뷰 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e5px2MivF_g"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "    # 토큰화 및 불용어 제거\n",
        "    new_sentence = mecab.morphs(new_sentence)\n",
        "    new_sentence = [word for word in new_sentence if not word in stopwords]\n",
        "\n",
        "    # 인코딩, 패딩\n",
        "    encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "    pad_new = pad_sequences(encoded, maxlen=max_len)\n",
        "\n",
        "    # 예측\n",
        "    score = float(loaded_model.predict(pad_new))\n",
        "\n",
        "    if (score > 0.5):\n",
        "        print(f'{score*100:.2f} % 확률로 긍정 리뷰입니다.')\n",
        "    else:\n",
        "        print(f'{(1-score)*100:.2f} % 확률로 부정 리뷰입니다.')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lQFQ5amx6mt",
        "outputId": "0f8e8736-b247-45f1-a4ed-0a41ad2d0a80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentiment_predict('이 상품 진짜 좋아요')\n",
        "sentiment_predict('이거 별로인데')\n",
        "sentiment_predict('사지 마셈')\n",
        "sentiment_predict('완전 좋아요 별점 무조건 5개 드립니다')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.05 % 확률로 긍정 리뷰입니다.\n",
            "96.84 % 확률로 부정 리뷰입니다.\n",
            "57.41 % 확률로 부정 리뷰입니다.\n",
            "95.53 % 확률로 긍정 리뷰입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZqAwFWx4NGa"
      },
      "source": [
        "# 글자 단위(Character-level)로 구현한 seq2seq 번역기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk7JC1k8x9U0",
        "outputId": "1ef97217-e375-42c6-971d-bc29f5aec25e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! wget -NP ./ https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/NLP/dataset/fra.txt"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-17 07:33:00--  https://raw.githubusercontent.com/MarigoldJ/ygl2/main/%ED%95%99%EC%8A%B5%EC%9E%90%EB%A3%8C/NLP/dataset/fra.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28543409 (27M) [text/plain]\n",
            "Saving to: ‘./fra.txt’\n",
            "\n",
            "fra.txt             100%[===================>]  27.22M  88.6MB/s    in 0.3s    \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2021-06-17 07:33:02 (88.6 MB/s) - ‘./fra.txt’ saved [28543409/28543409]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDXET1Fd4zJN",
        "outputId": "6f6ad168-695f-455a-91e6-b45a766070be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "file_path = './fra.txt'\n",
        "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "lines.sample(5)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>89847</th>\n",
              "      <td>Everyone is trying his best.</td>\n",
              "      <td>Chacun fait de son mieux.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87906</th>\n",
              "      <td>We were ordered to do that.</td>\n",
              "      <td>On nous a ordonné de faire ça.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177544</th>\n",
              "      <td>Whether rains or not, the game is going to be ...</td>\n",
              "      <td>Saison des pluies ou pas, la partie aura lieu.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76337</th>\n",
              "      <td>I know you're not serious.</td>\n",
              "      <td>Je sais que vous n'êtes pas sérieuse.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180878</th>\n",
              "      <td>It was such a wonderful movie that I saw it fi...</td>\n",
              "      <td>C'était un film tellement merveilleux que je l...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      eng  ...                                                 cc\n",
              "89847                        Everyone is trying his best.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "87906                         We were ordered to do that.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "177544  Whether rains or not, the game is going to be ...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "76337                          I know you're not serious.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "180878  It was such a wonderful movie that I saw it fi...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suJONIY_5T9G"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCu4gIAi6L71",
        "outputId": "fadc444e-8091-4635-dcf4-dd676da43509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "lines = lines[['eng', 'fra']][:50000]   # 5만개 샘플 사용\n",
        "lines.sample(5)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27003</th>\n",
              "      <td>You're productive.</td>\n",
              "      <td>Vous êtes productif.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14287</th>\n",
              "      <td>I'm not unhappy.</td>\n",
              "      <td>Je ne suis pas malheureux.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34885</th>\n",
              "      <td>I must get it fixed.</td>\n",
              "      <td>Je dois le faire réparer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1606</th>\n",
              "      <td>Answer Tom.</td>\n",
              "      <td>Répondez à Tom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5193</th>\n",
              "      <td>I've decided.</td>\n",
              "      <td>J'ai décidé.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        eng                         fra\n",
              "27003    You're productive.        Vous êtes productif.\n",
              "14287      I'm not unhappy.  Je ne suis pas malheureux.\n",
              "34885  I must get it fixed.   Je dois le faire réparer.\n",
              "1606            Answer Tom.             Répondez à Tom.\n",
              "5193          I've decided.                J'ai décidé."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GpDK9m06dn3",
        "outputId": "c3e6fe8b-6682-4bfc-fc7d-e9104c851309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "# 시작 토근과 종료 토근 추가\n",
        "sos_token = '\\t'\n",
        "eos_token = '\\n'\n",
        "lines.fra = lines.fra.apply(lambda x: '\\t' + x + '\\n')\n",
        "print('전체 샘플의 수 :', len(lines))\n",
        "lines.sample(5)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48134</th>\n",
              "      <td>I really like it, too.</td>\n",
              "      <td>\\tJe l'aime également beaucoup.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30707</th>\n",
              "      <td>That's one of them.</td>\n",
              "      <td>\\tIl s'agit de l'une des leurs.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33460</th>\n",
              "      <td>Do you want to talk?</td>\n",
              "      <td>\\tVoulez-vous parler ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36289</th>\n",
              "      <td>Our allies are weak.</td>\n",
              "      <td>\\tNos alliées sont faibles.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32837</th>\n",
              "      <td>You're so paranoid.</td>\n",
              "      <td>\\tTu es tellement paranoïaque !\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          eng                                fra\n",
              "48134  I really like it, too.  \\tJe l'aime également beaucoup.\\n\n",
              "30707     That's one of them.  \\tIl s'agit de l'une des leurs.\\n\n",
              "33460    Do you want to talk?           \\tVoulez-vous parler ?\\n\n",
              "36289    Our allies are weak.      \\tNos alliées sont faibles.\\n\n",
              "32837     You're so paranoid.  \\tTu es tellement paranoïaque !\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2rGKp8x7EHv",
        "outputId": "3a166c7c-2c09-40a5-a508-4d2e9daef5f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 영어 토큰화\n",
        "eng_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "eng_tokenizer.fit_on_texts(lines.eng)\n",
        "# 5만개 행을 가진 eng의 각 행에 토큰화 수행\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "print(input_text[:3])\n",
        "\n",
        "# 프랑스어 토큰화\n",
        "fra_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "fra_tokenizer.fit_on_texts(lines.fra)\n",
        "# 5만개 행을 가진 eng의 각 행에 토큰화 수행\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "print(target_text[:3])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]\n",
            "[[10, 19, 5, 1, 31, 11], [10, 15, 5, 12, 16, 29, 2, 14, 11], [10, 26, 9, 8, 28, 2, 1, 31, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD7KzT9k7stV",
        "outputId": "f1a6b2ee-6cb7-44c6-94be-043ec44fd6e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 단어장의 크기 : 52\n",
            "프랑스어 단어장의 크기 : 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga4z_pVf74OD",
        "outputId": "cc0c550e-5467-40f0-f792-efdc76f54f7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_eng_seq_len = max([len(l) for l in input_text])\n",
        "max_fra_seq_len = max([len(l) for l in target_text])\n",
        "\n",
        "print('영어 시퀀스의 최대 길이 :', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이 :', max_fra_seq_len)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 시퀀스의 최대 길이 : 22\n",
            "프랑스어 시퀀스의 최대 길이 : 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imlBaftS8Sny",
        "outputId": "db18e3e9-1ca7-4ea0-a8d7-62fc42ab8982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 정리\n",
        "print('전체 샘플의 수 :', len(lines))\n",
        "print()\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
        "print()\n",
        "print('영어 시퀀스의 최대 길이 :', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이 :', max_fra_seq_len)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n",
            "\n",
            "영어 단어장의 크기 : 52\n",
            "프랑스어 단어장의 크기 : 73\n",
            "\n",
            "영어 시퀀스의 최대 길이 : 22\n",
            "프랑스어 시퀀스의 최대 길이 : 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU0aMqOI84Iz",
        "outputId": "8ab90943-4e0b-4190-9ecd-61488c3f01a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_input = input_text\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[char for char in line if char != fra_tokenizer.word_index[eos_token]] for line in target_text]\n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[char for char in line if char != fra_tokenizer.word_index[sos_token]] for line in target_text]\n",
        "\n",
        "print(decoder_input[:3])    # <eos> 토큰 제거\n",
        "print(decoder_target[:3])   # <sos> 토큰 제거\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 19, 5, 1, 31], [10, 15, 5, 12, 16, 29, 2, 14], [10, 26, 9, 8, 28, 2, 1, 31]]\n",
            "[[19, 5, 1, 31, 11], [15, 5, 12, 16, 29, 2, 14, 11], [26, 9, 8, 28, 2, 1, 31, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZaRN9Ed9kfg",
        "outputId": "e616b0cd-a463-460c-c9a2-6fa7fb0311c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_fra_seq_len, padding='post')\n",
        "\n",
        "print('영어 데이터의 크기(shape) :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 :', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 :', np.shape(decoder_target))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기(shape) : (50000, 22)\n",
            "프랑스어 입력데이터의 크기 : (50000, 74)\n",
            "프랑스어 출력데이터의 크기 : (50000, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH9oD0ws-r3K",
        "outputId": "5af71fe7-509f-4924-a415-91240240ba33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(encoder_input[0])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trc54VkY-unH",
        "outputId": "4a911673-4fa5-45a9-cf99-a343163d266b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# one-hot encoding\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)\n",
        "\n",
        "print('영어 데이터의 크기(shape) :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 :', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 :', np.shape(decoder_target))\n",
        "# (샘플의 수, 샘플의 길이, 단어장의 크기)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기(shape) : (50000, 22, 52)\n",
            "프랑스어 입력데이터의 크기 : (50000, 74, 73)\n",
            "프랑스어 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGusF2Rf-7LZ",
        "outputId": "21be42ad-95f0-4769-81bb-a2a9176c9fc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('영어 학습 데이터의 크기 :', np.shape(encoder_input_train))\n",
        "print('프랑스어 학습 입력데이터의 크기 :', np.shape(decoder_input_train))\n",
        "print('프랑스어 학습 출력데이터의 크기 :', np.shape(decoder_target_train))\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 학습 데이터의 크기 : (47000, 22, 52)\n",
            "프랑스어 학습 입력데이터의 크기 : (47000, 74, 73)\n",
            "프랑스어 학습 출력데이터의 크기 : (47000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJE-d04JAHF3"
      },
      "source": [
        "## 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyox50khAEPT"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PORgPUnkANWe"
      },
      "source": [
        "# LSTM 셀의 마지막 time stem의 hidden state와 cell state를\n",
        "# 디코더 LSTM의 첫번째 hidden state와 cell state로 전달해주자\n",
        "\n",
        "encoder_inputs = Input(shape=(None, eng_vocab_size))    # 입력 텐서 생성\n",
        "encoder_lstm = LSTM(units=256, return_state=True)       # hidden state 256인 LSTM 생성\n",
        "_, state_h, state_c = encoder_lstm(encoder_inputs)      # 디코더로 전달할 state들을 반환 (encoder_output은 이때 불필요)\n",
        "encoder_states = [state_h, state_c]                     # 전달할 state를 별도로 저장\n",
        "\n",
        "decoder_inputs = Input(shape=(None, fra_vocab_size))                                    # 입력 텐서 생성\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)                # hidden state size 256 디코더 LSTM 생성\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)      # decoder output은 모든 timestep의 hidden state\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JTbvA_bBD0p"
      },
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEPcgTCdCRr4",
        "outputId": "41b1ca99-4a84-4251-8347-26fcf0fd7715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 52)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 316416      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  337920      input_3[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 73)     18761       lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 673,097\n",
            "Trainable params: 673,097\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDT_YFZ6CmWk",
        "outputId": "717306b9-066c-4f05-eb46-eef0c61ce556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=30)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "368/368 [==============================] - 9s 17ms/step - loss: 0.9052 - val_loss: 0.7943\n",
            "Epoch 2/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.5621 - val_loss: 0.6450\n",
            "Epoch 3/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.4612 - val_loss: 0.5635\n",
            "Epoch 4/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.4053 - val_loss: 0.5134\n",
            "Epoch 5/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.3686 - val_loss: 0.4713\n",
            "Epoch 6/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.3414 - val_loss: 0.4589\n",
            "Epoch 7/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.3201 - val_loss: 0.4298\n",
            "Epoch 8/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.3030 - val_loss: 0.4151\n",
            "Epoch 9/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.2890 - val_loss: 0.4088\n",
            "Epoch 10/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2774 - val_loss: 0.3900\n",
            "Epoch 11/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2672 - val_loss: 0.3830\n",
            "Epoch 12/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.2583 - val_loss: 0.3774\n",
            "Epoch 13/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.2504 - val_loss: 0.3761\n",
            "Epoch 14/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2434 - val_loss: 0.3678\n",
            "Epoch 15/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2369 - val_loss: 0.3670\n",
            "Epoch 16/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.2310 - val_loss: 0.3635\n",
            "Epoch 17/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2256 - val_loss: 0.3616\n",
            "Epoch 18/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2204 - val_loss: 0.3562\n",
            "Epoch 19/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2157 - val_loss: 0.3586\n",
            "Epoch 20/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2113 - val_loss: 0.3586\n",
            "Epoch 21/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2071 - val_loss: 0.3598\n",
            "Epoch 22/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.2031 - val_loss: 0.3561\n",
            "Epoch 23/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.1995 - val_loss: 0.3606\n",
            "Epoch 24/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.1957 - val_loss: 0.3614\n",
            "Epoch 25/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.1925 - val_loss: 0.3598\n",
            "Epoch 26/30\n",
            "368/368 [==============================] - 6s 15ms/step - loss: 0.1891 - val_loss: 0.3622\n",
            "Epoch 27/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.1859 - val_loss: 0.3612\n",
            "Epoch 28/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.1830 - val_loss: 0.3621\n",
            "Epoch 29/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.1801 - val_loss: 0.3661\n",
            "Epoch 30/30\n",
            "368/368 [==============================] - 6s 16ms/step - loss: 0.1774 - val_loss: 0.3689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7bd398b150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebfSqLDPGAd7"
      },
      "source": [
        "## 모델 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIwDAkfRGCTk"
      },
      "source": [
        "* 훈련시에 학습해야할 타겟 문장을 디코더 모델의 입력, 출력 시퀀스로 넣어주고, 디코더 모델이 타겟문장을 한꺼번에 출력하게 할 수 있습니다.\n",
        "* 그러나 테스트 단계는 불가능!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfC-ZyeoGVO6"
      },
      "source": [
        "* 테스트 단계에서 디코더 동작 순서\n",
        "    1. 인코더에 입력 문장을 넣어 마지막 time step의 hidden, cell state를 얻는다.\n",
        "    2. 토큰인 \\t를 디코더에 입력한다.\n",
        "    3. 이전 timestep의 출력층의 예측결과를 현재 timestep의 입력으로 한다.\n",
        "    4. 3을 반복하다가 토큰인 \\n가 예측되면 이를 중단한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0HpzR0jDQ2S",
        "outputId": "6c922e73-b58d-4fe7-b413-11f6899ca280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None, 52)]        0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 256), (None, 256) 316416    \n",
            "=================================================================\n",
            "Total params: 316,416\n",
            "Trainable params: 316,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go-dSixAGuiv"
      },
      "source": [
        "# 이전 timestep\n",
        "decoder_state_input_h = Input(shape=(256,))     # 이전 timestep의 hidden state\n",
        "decoder_state_input_c = Input(shape=(256,))     # 이전 timestep의 cell state\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]   # 이전 timestep의 state들 저장\n",
        "\n",
        "# 현재 timestep\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs) # 이전 state를 현재 timestep의 state로 사용\n",
        "decoder_states = [state_h, state_c]             # 현재 timestep의 state를 저장\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pja1a0LHPf2",
        "outputId": "1cd82fe7-79e4-4a17-b7ff-6e85e37dd9e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model= Model(inputs=[decoder_inputs] + decoder_state_inputs, outputs=[decoder_outputs]+decoder_states)\n",
        "decoder_model.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  337920      input_3[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 73)     18761       lstm_2[2][0]                     \n",
            "==================================================================================================\n",
            "Total params: 356,681\n",
            "Trainable params: 356,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHVjwqQtICas"
      },
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-MU6Vq7IPJP"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 \n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "    target_seq[0, 0, fra2idx['\\t']] = 1\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        # 이전 timestep의 상태 state_value를 현재 timestep의 초기 state로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 index -> fra 로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "        # 현재 timestep의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단\n",
        "        if (sampled_char == '\\n') or (len(decoded_sentence) > max_fra_seq_len):\n",
        "            stop_condition = True\n",
        "        \n",
        "        # 현재 timestep의 예측 결과를 다음 timestep의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1\n",
        "\n",
        "        # 현재 timestep의 state를 다음 timestep의 state로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lqv8b_QJUaW",
        "outputId": "8db11e2b-d0e8-449a-88ed-7067c2bd6ad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "    # 입력 문장의 인덱스 (자유롭게 바꿔서 출력해 보세요)\n",
        "    input_seq = encoder_input[seq_index:seq_index+1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "    print('-' * 40)\n",
        "    print('입력 문장 :', lines.eng[seq_index])\n",
        "    print('정답 문장 :', lines.fra[seq_index][1:len(lines.fra[seq_index]) - 1])\n",
        "    print('번역기가 번역한 문장 :', decoded_sentence[:len(decoded_sentence) - 1])\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "입력 문장 : Hi.\n",
            "정답 문장 : Salut !\n",
            "번역기가 번역한 문장 : salut !\n",
            "----------------------------------------\n",
            "입력 문장 : I won!\n",
            "정답 문장 : Je l'ai emporté !\n",
            "번역기가 번역한 문장 : j'ai appelé !\n",
            "----------------------------------------\n",
            "입력 문장 : I fled.\n",
            "정답 문장 : J'ai fui.\n",
            "번역기가 번역한 문장 : j'ai oublié.\n",
            "----------------------------------------\n",
            "입력 문장 : Hug Tom.\n",
            "정답 문장 : Fais un câlin à Tom.\n",
            "번역기가 번역한 문장 : salutez !\n",
            "----------------------------------------\n",
            "입력 문장 : I give in.\n",
            "정답 문장 : Je donne ma langue au chat.\n",
            "번역기가 번역한 문장 : je me suis rendu.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29VJEveEJ6ni"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}